{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5f3695",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos - Diabetes Gestacional (GDM)\n",
    "\n",
    "**Universidad de Magallanes**  \n",
    "**Facultad de Ingenier√≠a, Departamento de Ingenier√≠a en Computaci√≥n**  \n",
    "**Asignatura:** Matem√°tica para Ciencias de la Computaci√≥n  \n",
    "**Profesor:** David Medina Ortiz  \n",
    "\n",
    "---\n",
    "\n",
    "**Estudiante(s):** [Nombre(s) del/los estudiante(s)]  \n",
    "**Fecha de entrega:** 15 de noviembre de 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## Tabla de Progreso Global\n",
    "\n",
    "| Secci√≥n | T√≠tulo | Progreso | Estado |\n",
    "|---------|--------|----------|--------|\n",
    "| 1 | Descripci√≥n General del Dataset | 100% | ‚úÖ |\n",
    "| 2.1 | An√°lisis Exploratorio de Datos (EDA) | 100% | ‚úÖ |\n",
    "| 2.2 | Intervalos de Confianza | 54% | üü° |\n",
    "| 2.3 | Pruebas de Hip√≥tesis | 8% | üî¥ |\n",
    "| 2.4 | Evaluaci√≥n de Normalidad | 85% | üü¢ |\n",
    "| 2.5 | An√°lisis Bivariado | 100% | ‚úÖ |\n",
    "| 2.6 | Interpretaci√≥n Cl√≠nica y Conclusiones | 0% | üî¥ |\n",
    "| 3 | Entregables y Archivos | 100% | ‚úÖ |\n",
    "| **GLOBAL** | **Progreso Total** | **68%** | üü° |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Actualizaci√≥n: Migraci√≥n Completada\n",
    "\n",
    "**Fecha:** 11 de noviembre de 2025  \n",
    "**Migraci√≥n desde:** `1_check_data.ipynb`  \n",
    "\n",
    "### C√≥digo restaurado:\n",
    "- ‚úÖ Sistema completo de detecci√≥n de outliers (IQR + 3 variantes Isolation Forest)\n",
    "- ‚úÖ Sistema de votaci√≥n y filtrado de outliers (df_filter creado)\n",
    "- ‚úÖ Visualizaciones completas (histogramas, boxplots, violinplots)\n",
    "- ‚úÖ An√°lisis bivariado completo (correlaciones Pearson/Spearman, por grupo, diferencias)\n",
    "- ‚úÖ Pairplot comprehensivo\n",
    "\n",
    "**Resultado:** Notebook funcional con todas las dependencias resueltas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64237ba6",
   "metadata": {},
   "source": [
    "# 1. Descripci√≥n General del Dataset\n",
    "\n",
    "## Contexto\n",
    "\n",
    "Este trabajo utiliza un **dataset sint√©tico** que simula informaci√≥n cl√≠nica del **primer trimestre del embarazo** para el estudio de la **diabetes gestacional (GDM)**. El objetivo es caracterizar estad√≠sticamente los datos y explorar asociaciones entre variables cl√≠nicas y el riesgo de desarrollar GDM.\n",
    "\n",
    "## Caracter√≠sticas del Dataset\n",
    "\n",
    "- **N**: Aproximadamente 1500 registros de pacientes embarazadas\n",
    "- **Variables incluidas**:\n",
    "  - **Cl√≠nicas**: edad, IMC pregestacional, presi√≥n arterial (sist√≥lica, diast√≥lica, MAP), semanas de gestaci√≥n\n",
    "  - **Bioqu√≠micas**: FPG (glucosa en ayunas), HbA1c, insulina, HOMA-IR, triglic√©ridos, HDL\n",
    "  - **Factores de riesgo**: paridad, antecedentes familiares de diabetes tipo 2, GDM previa, PCOS, tabaquismo\n",
    "  - **Estilo de vida**: nivel de actividad f√≠sica, puntuaci√≥n de dieta (0-100)\n",
    "  - **Variable objetivo**: `label_gdm` (0 = No GDM, 1 = GDM)\n",
    "\n",
    "## Caracter√≠sticas Especiales\n",
    "\n",
    "- **Datos faltantes**: Presencia de valores nulos con patrones MCAR (Missing Completely At Random) y MAR (Missing At Random)\n",
    "- **Outliers**: El dataset contiene valores at√≠picos que requieren identificaci√≥n y tratamiento\n",
    "- **Desbalance de clases**: Aproximadamente 17% de casos positivos de GDM\n",
    "- **Tipos de variables**: Mixto (continuas, discretas y categ√≥ricas binarias)\n",
    "\n",
    "## Objetivo del An√°lisis\n",
    "\n",
    "Realizar un an√°lisis exploratorio exhaustivo que permita:\n",
    "1. Caracterizar la distribuci√≥n de las variables\n",
    "2. Identificar patrones y asociaciones relevantes\n",
    "3. Comparar grupos (GDM vs No-GDM)\n",
    "4. Evaluar supuestos estad√≠sticos\n",
    "5. Generar insights cl√≠nicos para la comprensi√≥n del riesgo de GDM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0aa53b",
   "metadata": {},
   "source": [
    "# 2. Actividades Desarrolladas\n",
    "\n",
    "Esta secci√≥n contiene el an√°lisis exploratorio organizado por subsecciones seg√∫n la gu√≠a pr√°ctica.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ad0a9",
   "metadata": {},
   "source": [
    "## 2.1 An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "**Estado**: ‚úÖ 100% completado - **COMPLETO**  \n",
    "**Actualizaci√≥n:** C√≥digo migrado completamente desde `1_check_data.ipynb`\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Carga de datos y verificaci√≥n de dimensiones\n",
    "- ‚úÖ An√°lisis de tipos de datos\n",
    "- ‚úÖ Detecci√≥n de valores faltantes\n",
    "- ‚úÖ Estad√≠stica descriptiva (media, mediana, IQR, percentiles)\n",
    "- ‚úÖ **Detecci√≥n de outliers por IQR** (m√©todo check_is_outlier)\n",
    "- ‚úÖ **Detecci√≥n con Isolation Forest (3 variantes)**:\n",
    "  - Solo variables categ√≥ricas\n",
    "  - Solo variables continuas\n",
    "  - Todas las variables\n",
    "- ‚úÖ **Sistema de votaci√≥n de outliers (4 m√©todos)**\n",
    "- ‚úÖ **Filtrado de outliers (vote_outlier < 3)**\n",
    "- ‚úÖ **Creaci√≥n de df_filter** (dataset limpio)\n",
    "- ‚úÖ **Visualizaciones completas:**\n",
    "  - Histogramas con KDE por grupo GDM\n",
    "  - Boxplots por grupo GDM\n",
    "  - Violinplots por grupo GDM\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Interpretaci√≥n textual detallada por variable (opcional)\n",
    "- ‚è≥ Documentaci√≥n adicional de estrategia para outliers (opcional)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585aa278",
   "metadata": {},
   "source": [
    "### Importaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from auxiliar_functions import *\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9c3e4",
   "metadata": {},
   "source": [
    "### Carga y exploraci√≥n inicial del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f52dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "df_data = pd.read_csv(\"gdm_first_trimester_ml_dataset.csv\")\n",
    "\n",
    "# Primeras filas\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "print(f\"Dimensiones: {df_data.shape}\")\n",
    "print(f\"Total de registros: {df_data.shape[0]}\")\n",
    "print(f\"Total de variables: {df_data.shape[1]}\")\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de la variable objetivo\n",
    "print(\"Distribuci√≥n de GDM:\")\n",
    "print(df_data[\"label_gdm\"].value_counts())\n",
    "print(f\"\\nProporci√≥n de casos positivos: {df_data['label_gdm'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos\n",
    "print(\"Tipos de datos por variable:\")\n",
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n de variable categ√≥rica: PCOS\n",
    "# Utilidad: Verificar cu√°ntos valores √∫nicos tiene esta variable binaria (0/1)\n",
    "# Esto confirma que PCOS es efectivamente una variable dicot√≥mica sin valores an√≥malos\n",
    "print(\"üîç Exploraci√≥n de la variable PCOS (S√≠ndrome de Ovario Poliqu√≠stico):\")\n",
    "print(f\"Valores √∫nicos: {df_data['pcos'].unique()}\")\n",
    "print(f\"N√∫mero de valores √∫nicos: {df_data['pcos'].unique().shape[0]}\")\n",
    "print(\"\\nDistribuci√≥n de PCOS:\")\n",
    "print(df_data[\"pcos\"].value_counts())\n",
    "print(f\"\\nüìä Proporci√≥n de pacientes con PCOS: {df_data['pcos'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d8bb4",
   "metadata": {},
   "source": [
    "### An√°lisis de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls = df_data.isna().astype(int)\n",
    "df_summary_null = generate_df_counts(df_nulls, columns_name=[\"descriptor\", \"count_Nulls\", \"count_Falses\"])\n",
    "print(\"Resumen de valores faltantes:\")\n",
    "df_summary_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n detallada: Visualizar matriz completa de valores faltantes\n",
    "# Utilidad: Permite inspeccionar visualmente patrones de datos faltantes por registro\n",
    "# Cada fila representa un paciente, cada columna una variable (1=faltante, 0=presente)\n",
    "print(\"üìã Primeras 10 filas de la matriz de valores faltantes:\")\n",
    "print(\"(1 = dato faltante, 0 = dato presente)\\n\")\n",
    "df_nulls.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27535ff4",
   "metadata": {},
   "source": [
    "### Estad√≠stica descriptiva\n",
    "\n",
    "Definimos las variables categ√≥ricas que se excluir√°n del an√°lisis descriptivo de variables continuas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_ignore = [\n",
    "    \"parity\", \n",
    "    \"family_history_t2d\",\n",
    "    \"previous_gdm\",\n",
    "    \"pcos\", \n",
    "    \"smoking_first_trimester\",\n",
    "    \"label_gdm\",\n",
    "    \"physical_activity_level\"\n",
    "]\n",
    "\n",
    "print(\"Variables categ√≥ricas/binarias a excluir del an√°lisis descriptivo:\")\n",
    "print(columns_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b36d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠stica descriptiva para todas las variables\n",
    "print(\"Estad√≠sticas descriptivas del dataset completo:\")\n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb410c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_descriptors = []\n",
    "\n",
    "for column in df_data.columns:\n",
    "    if column not in columns_to_ignore:\n",
    "        descriptive_values = df_data[column].describe()\n",
    "\n",
    "        IQR = descriptive_values[\"75%\"] - descriptive_values[\"25%\"]\n",
    "        min_value, max_value = get_range_outlier(\n",
    "            descriptive_values[\"25%\"], \n",
    "            descriptive_values[\"75%\"], \n",
    "            IQR)\n",
    "\n",
    "        row = {\n",
    "            \"descriptor\" : column,\n",
    "            \"mean\":descriptive_values[\"mean\"],\n",
    "            \"std\" :descriptive_values[\"std\"],\n",
    "            \"median\" : descriptive_values[\"50%\"],\n",
    "            \"IQR\" : IQR,\n",
    "            \"25%\" : descriptive_values[\"25%\"],\n",
    "            \"75%\" :descriptive_values[\"75%\"],\n",
    "            \"min_value_for_outlier\" : min_value,\n",
    "            \"max_value_for_outlier\" : max_value\n",
    "\n",
    "        }\n",
    "        statistical_descriptors.append(row)\n",
    "\n",
    "df_statistical = pd.DataFrame(statistical_descriptors)\n",
    "print(\"Estad√≠sticas descriptivas con IQR y umbrales para outliers:\")\n",
    "df_statistical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b06d9",
   "metadata": {},
   "source": [
    "### Detecci√≥n de outliers\n",
    "\n",
    "**Nota**: Se implementa detecci√≥n por IQR e Isolation Forest con sistema de votaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecci√≥n de outliers por m√©todo IQR\n",
    "df_outliers = pd.DataFrame()\n",
    "\n",
    "for column in df_data.columns:\n",
    "    if column not in columns_to_ignore:\n",
    "        \n",
    "        df_filter = df_statistical[df_statistical[\"descriptor\"] == column]\n",
    "        df_filter.reset_index(inplace=True)\n",
    "\n",
    "        min_value, max_value = df_filter[\"min_value_for_outlier\"][0], df_filter[\"max_value_for_outlier\"][0]\n",
    "\n",
    "        df_outliers[column] = df_data[column].apply(lambda x: check_is_outlier(x, min_value, max_value))\n",
    "\n",
    "print(\"Detecci√≥n de outliers por IQR completada\")\n",
    "print(f\"Dimensiones de df_outliers: {df_outliers.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a enteros y generar resumen\n",
    "df_outliers = df_outliers.astype(int)\n",
    "df_summary_outlier = generate_df_counts(df_outliers, columns_name=[\"descriptor\", \"count_Outlier\", \"count_NotOutlier\"])\n",
    "print(\"\\nResumen de outliers detectados por IQR:\")\n",
    "df_summary_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b65685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columna con conteo de outliers por fila\n",
    "df_outliers[\"outlier_by_IQR\"] = df_outliers.sum(axis=1)\n",
    "print(\"\\nDistribuci√≥n de n√∫mero de outliers por registro:\")\n",
    "print(df_outliers[\"outlier_by_IQR\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da691f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n detallada: Ejemplo de detecci√≥n en una variable espec√≠fica\n",
    "# Utilidad: Verificar la correcta aplicaci√≥n del m√©todo IQR en una variable clave\n",
    "print(\"üî¨ Ejemplo de detecci√≥n en triglic√©ridos:\")\n",
    "print(\"Distribuci√≥n de outliers (0=normal, 1=outlier):\")\n",
    "print(df_outliers[\"triglycerides_mmol_l\"].value_counts())\n",
    "print(f\"\\n‚ö†Ô∏è  Registros con triglic√©ridos at√≠picos: {df_outliers['triglycerides_mmol_l'].sum()}\")\n",
    "print(f\"‚úì Registros con triglic√©ridos normales: {(df_outliers['triglycerides_mmol_l'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af26337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Verificar estructura del dataframe de outliers\n",
    "# Utilidad: Confirmar que todas las variables continuas est√°n incluidas en el an√°lisis\n",
    "print(\"üìã Columnas incluidas en la detecci√≥n de outliers:\")\n",
    "print(df_outliers.columns.tolist())\n",
    "print(f\"\\nüìä Total de variables analizadas: {len(df_outliers.columns) - 1}\")  # -1 por outlier_by_IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fff822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n espec√≠fica: Casos extremos de paridad\n",
    "# Utilidad: Identificar valores poco comunes que podr√≠an ser outliers por s√≠ mismos\n",
    "# La paridad alta (‚â•5 embarazos) es cl√≠nicamente relevante para riesgo de GDM\n",
    "print(\"\\nüî¨ An√°lisis de casos extremos de paridad:\")\n",
    "paridad_extrema = df_data[df_data[\"parity\"] == 5]\n",
    "print(f\"Registros con paridad = 5: {len(paridad_extrema)}\")\n",
    "if len(paridad_extrema) > 0:\n",
    "    print(\"\\nPrimeros registros con paridad extrema:\")\n",
    "    print(paridad_extrema[[\"parity\", \"age_years\", \"bmi_prepreg_kg_m2\", \"label_gdm\"]].head())\n",
    "else:\n",
    "    print(\"No hay registros con paridad = 5 en el dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: An√°lisis de distribuci√≥n de todas las variables categ√≥ricas\n",
    "# Utilidad: Entender el balance de clases en variables binarias/categ√≥ricas\n",
    "# Esto es cr√≠tico antes de aplicar Isolation Forest para detectar combinaciones an√≥malas\n",
    "print(\"üìä DISTRIBUCI√ìN DE VARIABLES CATEG√ìRICAS/BINARIAS\")\n",
    "print(\"=\" * 70)\n",
    "for column in columns_to_ignore:\n",
    "    print(f\"\\nüîπ {column}:\")\n",
    "    print(df_data[column].value_counts().sort_index())\n",
    "    if column != \"label_gdm\":  # No calcular proporci√≥n para la etiqueta objetivo\n",
    "        try:\n",
    "            prop = df_data[column].mean()\n",
    "            print(f\"   Proporci√≥n de casos positivos: {prop:.2%}\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db925e46",
   "metadata": {},
   "source": [
    "#### Exploraci√≥n de variables categ√≥ricas\n",
    "\n",
    "Antes de aplicar Isolation Forest, es importante entender la distribuci√≥n de las variables categ√≥ricas/binarias que ser√°n analizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734913c7",
   "metadata": {},
   "source": [
    "#### Detecci√≥n con Isolation Forest\n",
    "\n",
    "Se implementan 3 estrategias de detecci√≥n con Isolation Forest:\n",
    "1. **Solo variables categ√≥ricas**: Detecta anomal√≠as en combinaciones inusuales de factores de riesgo\n",
    "2. **Solo variables continuas**: Identifica valores at√≠picos en mediciones cl√≠nicas\n",
    "3. **Todas las variables**: Combina ambos enfoques para una detecci√≥n integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Isolation Forest sobre variables categ√≥ricas\n",
    "data_categorical = df_data[columns_to_ignore]\n",
    "data_categorical = data_categorical.drop(columns=[\"label_gdm\"])\n",
    "\n",
    "isolation_instance = IsolationForest(random_state=42)\n",
    "isolation_instance.fit(data_categorical)\n",
    "data_categorical[\"is_isolated\"] = isolation_instance.predict(data_categorical)\n",
    "\n",
    "print(\"Isolation Forest - Solo categ√≥ricas:\")\n",
    "print(data_categorical[\"is_isolated\"].value_counts())\n",
    "print(f\"Outliers detectados: {(data_categorical['is_isolated'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Visualizar resultados del Isolation Forest en categ√≥ricas\n",
    "# Utilidad: Verificar qu√© combinaciones de factores de riesgo son consideradas an√≥malas\n",
    "# Permite identificar perfiles de pacientes con combinaciones inusuales de caracter√≠sticas\n",
    "print(\"üìã Primeras 10 filas con predicci√≥n de anomal√≠a (categ√≥ricas):\")\n",
    "print(\"Valores: 1 = normal, -1 = outlier/anomal√≠a\\n\")\n",
    "data_categorical.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Isolation Forest sobre solo valores continuos\n",
    "df_values = df_data.drop(columns=columns_to_ignore)\n",
    "\n",
    "isolation_instance = IsolationForest(random_state=42)\n",
    "isolation_instance.fit(df_values)\n",
    "df_values[\"is_isolated\"] = isolation_instance.predict(df_values)\n",
    "\n",
    "print(\"\\nIsolation Forest - Solo continuas:\")\n",
    "print(df_values[\"is_isolated\"].value_counts())\n",
    "print(f\"Outliers detectados: {(df_values['is_isolated'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Isolation Forest sobre todas las variables (excepto label_gdm)\n",
    "df_values_cat = df_data.drop(columns=[\"label_gdm\"])\n",
    "\n",
    "isolation_instance = IsolationForest(random_state=42)\n",
    "isolation_instance.fit(df_values_cat)\n",
    "df_values_cat[\"is_isolated\"] = isolation_instance.predict(df_values_cat)\n",
    "\n",
    "print(\"\\nIsolation Forest - Todas las variables:\")\n",
    "print(df_values_cat[\"is_isolated\"].value_counts())\n",
    "print(f\"Outliers detectados: {(df_values_cat['is_isolated'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87682102",
   "metadata": {},
   "source": [
    "#### Sistema de votaci√≥n para outliers\n",
    "\n",
    "Se combinan los 4 m√©todos de detecci√≥n:\n",
    "1. **IQR** (rango intercuart√≠lico)\n",
    "2. **IF sobre categ√≥ricas**\n",
    "3. **IF sobre continuas**\n",
    "4. **IF sobre todas las variables**\n",
    "\n",
    "Los registros se clasificar√°n seg√∫n el n√∫mero de m√©todos que los identifiquen como outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba58980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columnas de detecci√≥n de outliers al dataframe principal\n",
    "df_data[\"is_outlier_by_IQR\"] = df_outliers[\"outlier_by_IQR\"].values\n",
    "df_data[\"is_outlier_by_IF_all\"] = df_values_cat[\"is_isolated\"].values\n",
    "df_data[\"is_outlier_by_IF_just_values\"] = df_values[\"is_isolated\"].values\n",
    "df_data[\"is_outlier_by_IF_just_cat\"] = data_categorical[\"is_isolated\"].values\n",
    "\n",
    "print(\"Columnas de detecci√≥n agregadas al dataframe principal\")\n",
    "print(f\"Nuevas columnas: {['is_outlier_by_IQR', 'is_outlier_by_IF_all', 'is_outlier_by_IF_just_values', 'is_outlier_by_IF_just_cat']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Verificar integraci√≥n de m√©todos de detecci√≥n en el dataframe principal\n",
    "# Utilidad: Confirmar que todas las columnas de detecci√≥n se agregaron correctamente\n",
    "# y que el dataframe mantiene su integridad estructural\n",
    "print(\"üìã Verificaci√≥n de integraci√≥n de m√©todos de detecci√≥n:\")\n",
    "print(f\"Dimensiones del dataframe: {df_data.shape}\")\n",
    "print(f\"\\nüîç Nuevas columnas agregadas:\")\n",
    "detection_cols = ['is_outlier_by_IQR', 'is_outlier_by_IF_all', 'is_outlier_by_IF_just_values', 'is_outlier_by_IF_just_cat']\n",
    "for col in detection_cols:\n",
    "    if col in df_data.columns:\n",
    "        print(f\"  ‚úì {col}\")\n",
    "print(\"\\nüìä Primeras 5 filas con columnas de detecci√≥n:\")\n",
    "df_data[detection_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizar IQR: convertir conteo a binario (0 = no outlier, 1 = outlier)\n",
    "df_data[\"is_outlier_by_IQR\"] = df_data[\"is_outlier_by_IQR\"].apply(categorize_iqr)\n",
    "\n",
    "print(\"\\nDistribuci√≥n de outliers por IQR (categorizado):\")\n",
    "print(df_data[\"is_outlier_by_IQR\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapear valores de Isolation Forest: 1 (normal) ‚Üí 0, -1 (outlier) ‚Üí 1\n",
    "for column in [\"is_outlier_by_IF_all\", \"is_outlier_by_IF_just_values\", \"is_outlier_by_IF_just_cat\"]:\n",
    "    df_data[column] = df_data[column].replace({1:0, -1:1})\n",
    "\n",
    "print(\"\\nValores de Isolation Forest remapeados:\")\n",
    "print(\"  1 (normal) ‚Üí 0 (no outlier)\")\n",
    "print(\"  -1 (anomal√≠a) ‚Üí 1 (outlier)\")\n",
    "print(\"\\nDistribuci√≥n de outliers por IF (todas las variables):\")\n",
    "print(df_data[\"is_outlier_by_IF_all\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de votaci√≥n: sumar los 4 m√©todos (valores de 0 a 4)\n",
    "df_data[\"vote_outlier\"] = df_data[[\"is_outlier_by_IF_all\", \"is_outlier_by_IF_just_values\", \n",
    "                                     \"is_outlier_by_IF_just_cat\", \"is_outlier_by_IQR\"]].sum(axis=1)\n",
    "\n",
    "print(\"\\nüìä Distribuci√≥n de votos de outliers:\")\n",
    "print(df_data[\"vote_outlier\"].value_counts().sort_index())\n",
    "print(f\"\\nüîç Registros identificados como outliers por los 4 m√©todos: {(df_data['vote_outlier'] == 4).sum()}\")\n",
    "print(f\"‚ö†Ô∏è  Registros identificados como outliers por 3+ m√©todos: {(df_data['vote_outlier'] >= 3).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n detallada: An√°lisis de casos con m√°xima votaci√≥n de outliers\n",
    "# Utilidad: Identificar qu√© caracter√≠sticas tienen los registros m√°s an√≥malos\n",
    "# Estos son candidatos muy fuertes a ser outliers verdaderos que deben eliminarse\n",
    "print(\"üî¨ AN√ÅLISIS DE CASOS EXTREMOS (vote_outlier = 4):\")\n",
    "print(\"=\" * 70)\n",
    "casos_extremos = df_data[df_data[\"vote_outlier\"] == 4]\n",
    "if len(casos_extremos) > 0:\n",
    "    print(f\"Total de casos identificados por los 4 m√©todos: {len(casos_extremos)}\")\n",
    "    print(\"\\nüìä Muestra de registros extremos:\")\n",
    "    # Mostrar algunas variables clave para entender por qu√© son outliers\n",
    "    cols_interes = [\"age_years\", \"bmi_prepreg_kg_m2\", \"fpg_mmol_l\", \"hba1c_percent\", \n",
    "                    \"parity\", \"label_gdm\", \"vote_outlier\"]\n",
    "    print(casos_extremos[cols_interes].head(10))\n",
    "else:\n",
    "    print(\"‚úì No hay registros identificados como outliers por los 4 m√©todos simult√°neamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781730d1",
   "metadata": {},
   "source": [
    "#### Filtrado de outliers\n",
    "\n",
    "**Criterio:** Se eliminan registros identificados como outliers por 3 o m√°s m√©todos (vote_outlier ‚â• 3).\n",
    "\n",
    "Esta estrategia conservadora elimina solo los casos m√°s extremos, preservando la mayor parte de los datos para an√°lisis posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463234d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar outliers: mantener solo registros con vote_outlier < 3\n",
    "df_filter = df_data[df_data[\"vote_outlier\"] < 3].copy()\n",
    "\n",
    "print(f\"‚úÖ Dataset filtrado creado: df_filter\")\n",
    "print(f\"üìä Dimensiones originales: {df_data.shape}\")\n",
    "print(f\"üìä Dimensiones filtradas: {df_filter.shape}\")\n",
    "print(f\"üóëÔ∏è  Registros eliminados: {df_data.shape[0] - df_filter.shape[0]} ({((df_data.shape[0] - df_filter.shape[0]) / df_data.shape[0] * 100):.2f}%)\")\n",
    "print(f\"\\n‚úì Variable cr√≠tica 'df_filter' creada exitosamente para an√°lisis posteriores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b862d",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de datos por grupo GDM\n",
    "\n",
    "Se generan visualizaciones exploratorias para todas las variables continuas, comparando la distribuci√≥n entre pacientes con y sin diabetes gestacional (GDM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas con KDE para todas las variables continuas (3x5 subplots)\n",
    "_, axis = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "index = 1\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for column in df_statistical[\"descriptor\"].values:\n",
    "    sns.histplot(\n",
    "        data=df_filter, \n",
    "        x=column, \n",
    "        stat=\"count\",\n",
    "        fill=False, \n",
    "        kde=True, \n",
    "        hue=\"label_gdm\", \n",
    "        ax=axis[i][j])\n",
    "    \n",
    "    axis[i][j].set_xlabel(column, fontsize=8)\n",
    "    axis[i][j].set_ylabel(\"Count\", fontsize=8)\n",
    "    axis[i][j].tick_params(labelsize=7)\n",
    "\n",
    "    if index % 5 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "plt.suptitle(\"Distribuci√≥n de Variables Continuas por Grupo GDM (Histogramas + KDE)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24987d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para todas las variables continuas (3x5 subplots)\n",
    "_, axis = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "index = 1\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for column in df_statistical[\"descriptor\"].values:\n",
    "    sns.boxplot(\n",
    "        data=df_filter, \n",
    "        x=column, \n",
    "        fill=False, \n",
    "        hue=\"label_gdm\", \n",
    "        ax=axis[i][j])\n",
    "    \n",
    "    axis[i][j].set_xlabel(column, fontsize=8)\n",
    "    axis[i][j].tick_params(labelsize=7)\n",
    "\n",
    "    if index % 5 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "plt.suptitle(\"Comparaci√≥n de Distribuciones por Grupo GDM (Boxplots)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e84723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violinplots para todas las variables continuas (3x5 subplots)\n",
    "_, axis = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "index = 1\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for column in df_statistical[\"descriptor\"].values:\n",
    "    sns.violinplot(\n",
    "        data=df_filter, \n",
    "        x=column, \n",
    "        fill=False, \n",
    "        hue=\"label_gdm\", \n",
    "        ax=axis[i][j])\n",
    "    \n",
    "    axis[i][j].set_xlabel(column, fontsize=8)\n",
    "    axis[i][j].tick_params(labelsize=7)\n",
    "\n",
    "    if index % 5 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "plt.suptitle(\"Distribuci√≥n y Densidad por Grupo GDM (Violinplots)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d525017",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Intervalos de Confianza\n",
    "\n",
    "**Estado**: üü° 54% completado  \n",
    "**Pendiente**: IC para proporciones, diferencias de medias e interpretaci√≥n cl√≠nica\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Funciones de c√°lculo de IC implementadas en `auxiliar_functions.py`\n",
    "- ‚úÖ IC para media y varianza de IMC, FPG, HbA1c con m√∫ltiples tama√±os de muestra\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ IC para medias de: HDL, presi√≥n arterial (sist√≥lica, diast√≥lica, MAP), triglic√©ridos\n",
    "- ‚è≥ IC para proporciones (fumadoras, antecedentes familiares, PCOS, GDM previa)\n",
    "- ‚è≥ IC para diferencia de medias entre grupos GDM vs No-GDM\n",
    "- ‚è≥ Interpretaci√≥n cl√≠nica comparando con rangos de referencia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ff89c",
   "metadata": {},
   "source": [
    "### C√°lculo de intervalos de confianza para diferentes tama√±os de muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feee6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(10, 100, 10)  # Tama√±os de muestra de 10 a 100\n",
    "print(\"Tama√±os de muestra a evaluar:\")\n",
    "print(n)\n",
    "\n",
    "nro_tamanhos = n.size\n",
    "np.random.seed(42)\n",
    "\n",
    "# Intervalos de confianza\n",
    "for i in range(0, nro_tamanhos):\n",
    "    df_mini = pd.DataFrame()\n",
    "    picked_up_indexs = []\n",
    "    index = None\n",
    "\n",
    "    for j in range(0, int(n[i])):    \n",
    "        while index in picked_up_indexs:\n",
    "            index = np.random.randint(0, df_data.shape[0])\n",
    "            df_mini = pd.concat([df_mini, df_data.iloc[[index]]])\n",
    "        picked_up_indexs.append(index)\n",
    "    \n",
    "    # Intervalos de confianza para variables clave\n",
    "    interesting_descriptors_names = [\"bmi_prepreg_kg_m2\", \"fpg_mmol_l\", \"hba1c_percent\"]\n",
    "\n",
    "    for descriptor_name in interesting_descriptors_names:\n",
    "        descriptor = df_mini[descriptor_name]\n",
    "        descriptor_mean = descriptor.mean()\n",
    "        descriptor_std = descriptor.std()\n",
    "        IC_mean = calculate_ic_mean(descriptor_mean, descriptor_std, int(n[i]))\n",
    "        IC_std = calculate_ic_std(descriptor_std, int(n[i]))\n",
    "        print(f\"Para n={int(n[i])} el intervalo de confianza para la media (Œº) del descriptor '{descriptor_name}' es [{IC_mean[0]:.4f}, {IC_mean[1]:.4f}]\")\n",
    "        print(f\"Para n={int(n[i])} el intervalo de confianza para la varianza (œÉ¬≤) del descriptor '{descriptor_name}' es [{IC_std[0]:.4f}, {IC_std[1]:.4f}]\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c86ff4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Pruebas de Hip√≥tesis\n",
    "\n",
    "**Estado**: üî¥ 8% completado - **CR√çTICO**  \n",
    "**Pendiente**: Casi todas las pruebas de hip√≥tesis\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Funci√≥n `compare_two_groups_numeric` implementada (t-test/Welch/Mann-Whitney autom√°tico)\n",
    "- ‚úÖ Comparaci√≥n preliminar de presi√≥n arterial (sist√≥lica, diast√≥lica, MAP) entre grupos GDM\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Formular H‚ÇÄ y H‚ÇÅ para todas las comparaciones\n",
    "- ‚è≥ Comparar IMC, FPG, HbA1c entre GDM vs No-GDM\n",
    "- ‚è≥ Comparar dieta seg√∫n nivel de actividad f√≠sica (ANOVA/Kruskal-Wallis)\n",
    "- ‚è≥ Pruebas de proporciones (chi¬≤ o z): antecedentes familiares, PCOS, tabaquismo vs GDM\n",
    "- ‚è≥ Reportar tama√±o de efecto (d de Cohen o r) para todas las pruebas\n",
    "- ‚è≥ Interpretar resultados en contexto cl√≠nico\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a716d3b",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de presi√≥n arterial entre grupos GDM (ejemplo preliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_groups_numeric(df, y_col, group_col=\"label_gdm\", alpha=0.05, tail=\"two-sided\"):\n",
    "    \"\"\"\n",
    "    Compara una variable num√©rica (y_col) entre dos grupos binarios (group_col).\n",
    "    Verifica supuestos: normalidad por grupo (Shapiro) y homogeneidad (Levene).\n",
    "    Decide autom√°ticamente entre:\n",
    "      - t de Student cl√°sico (varianzas iguales)\n",
    "      - Welch t-test (varianzas desiguales)\n",
    "      - Mann‚ÄìWhitney U (si falla normalidad)\n",
    "    Retorna un dict con todo lo necesario para el informe.\n",
    "    \"\"\"\n",
    "    d = df[[y_col, group_col]].dropna()\n",
    "    g0 = d[d[group_col] == 0][y_col].astype(float).values\n",
    "    g1 = d[d[group_col] == 1][y_col].astype(float).values\n",
    "\n",
    "    # Hip√≥tesis\n",
    "    H0 = f\"Œº_{y_col}|GDM=0 == Œº_{y_col}|GDM=1\"\n",
    "    H1 = f\"Œº_{y_col}|GDM=0 != Œº_{y_col}|GDM=1\" if tail==\"two-sided\" else f\"Œº diferencias unilaterales ({tail})\"\n",
    "\n",
    "    # Normalidad por grupo (solo si n>=3)\n",
    "    sh0 = stats.shapiro(g0) if len(g0) >= 3 else (np.nan, np.nan)\n",
    "    sh1 = stats.shapiro(g1) if len(g1) >= 3 else (np.nan, np.nan)\n",
    "    normal_ok = (not np.isnan(sh0[1]) and sh0[1] > alpha) and (not np.isnan(sh1[1]) and sh1[1] > alpha)\n",
    "\n",
    "    # Homogeneidad de varianzas (Levene)\n",
    "    lev = stats.levene(g0, g1, center='median')\n",
    "    equal_var = lev.pvalue > alpha\n",
    "\n",
    "    # Elecci√≥n de prueba\n",
    "    if normal_ok:\n",
    "        res = stats.ttest_ind(g0, g1, equal_var=equal_var, alternative=\"two-sided\")\n",
    "        test_name = \"t-test (Welch)\" if not equal_var else \"t-test (varianzas iguales)\"\n",
    "        stat, p = res.statistic, res.pvalue\n",
    "    else:\n",
    "        res = stats.mannwhitneyu(g0, g1, alternative=\"two-sided\")\n",
    "        test_name = \"Mann‚ÄìWhitney U\"\n",
    "        stat, p = res.statistic, res.pvalue\n",
    "\n",
    "    decision = \"Rechazo H0\" if p < alpha else \"No rechazo H0\"\n",
    "\n",
    "    return {\n",
    "        \"variable\": y_col,\n",
    "        \"n_gdm0\": len(g0), \"mean_gdm0\": np.mean(g0), \"sd_gdm0\": np.std(g0, ddof=1),\n",
    "        \"n_gdm1\": len(g1), \"mean_gdm1\": np.mean(g1), \"sd_gdm1\": np.std(g1, ddof=1),\n",
    "        \"shapiro_g0_p\": (np.nan if np.isnan(sh0[1]) else sh0[1]),\n",
    "        \"shapiro_g1_p\": (np.nan if np.isnan(sh1[1]) else sh1[1]),\n",
    "        \"levene_p\": lev.pvalue,\n",
    "        \"test\": test_name, \"stat\": stat, \"p_value\": p,\n",
    "        \"alpha\": alpha, \"decision\": decision,\n",
    "        \"H0\": H0, \"H1\": H1\n",
    "    }\n",
    "\n",
    "# Ejemplo: Comparaci√≥n de presi√≥n arterial\n",
    "print(\"Comparaci√≥n de presi√≥n arterial entre grupos GDM vs No-GDM:\")\n",
    "print(\"=\" * 70)\n",
    "for col in [\"systolic_bp_mmHg\", \"diastolic_bp_mmHg\", \"map_mmHg\"]:\n",
    "    out = compare_two_groups_numeric(df_data, y_col=col, group_col=\"label_gdm\", alpha=0.05)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87efb4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Evaluaci√≥n de Normalidad\n",
    "\n",
    "**Estado**: üü¢ 85% completado - **CASI COMPLETO**  \n",
    "**Pendiente**: Solo visualizaciones (QQ-plots) y transformaciones\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Prueba de Shapiro-Wilk para todas las variables continuas\n",
    "- ‚úÖ Prueba de Kolmogorov-Smirnov (Lilliefors) para todas las variables continuas\n",
    "- ‚úÖ Resumen tabular de resultados con decisi√≥n (Normal / No normal)\n",
    "- ‚úÖ Comparaci√≥n de ambos tests y priorizaci√≥n de Shapiro-Wilk\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Generar QQ-plots para cada variable continua\n",
    "- ‚è≥ Histogramas con curva normal superpuesta\n",
    "- ‚è≥ Probar transformaciones (log, Box-Cox) en variables asim√©tricas\n",
    "- ‚è≥ Re-evaluar normalidad post-transformaci√≥n\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c471b0",
   "metadata": {},
   "source": [
    "### Pruebas de normalidad: Shapiro-Wilk y Kolmogorov-Smirnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables = [\n",
    "    \"age_years\", \"bmi_prepreg_kg_m2\", \"systolic_bp_mmHg\", \"diastolic_bp_mmHg\", \n",
    "    \"map_mmHg\", \"gestational_weeks\", \"fpg_mmol_l\", \"hba1c_percent\", \n",
    "    \"insulin_uIU_ml\", \"homa_ir\", \"triglycerides_mmol_l\", \"hdl_mmol_l\", \n",
    "    \"physical_activity_level\", \"diet_score_0_100\"\n",
    "]\n",
    "\n",
    "# Inicializar estructuras\n",
    "clean_data_descriptors = []\n",
    "n_val = []\n",
    "n_invalid = []\n",
    "\n",
    "# Limpiar NaN por variable\n",
    "for var in continuous_variables:\n",
    "    valid_data = df_data[var].dropna()\n",
    "    n_validos = valid_data.size\n",
    "    n_faltantes = df_data[var].isna().sum()\n",
    "\n",
    "    clean_data_descriptors.append(valid_data)\n",
    "    n_val.append(n_validos)\n",
    "    n_invalid.append(n_faltantes)\n",
    "\n",
    "# Prueba de normalidad\n",
    "normality_results = []\n",
    "alpha = 0.05\n",
    "\n",
    "# Evaluar cada variable\n",
    "for idx, var in enumerate(continuous_variables):\n",
    "    x = clean_data_descriptors[idx]\n",
    "\n",
    "    # Shapiro‚ÄìWilk\n",
    "    W, p_sw = stats.shapiro(x)\n",
    "    \n",
    "    # KS-Lilliefors (usando par√°metros estimados)\n",
    "    mu, sigma = x.mean(), x.std(ddof=1)\n",
    "    D, p_ks = stats.kstest(x, 'norm', args=(mu, sigma))\n",
    "    \n",
    "    # Decisi√≥n\n",
    "    decision_sw = \"Normal\" if p_sw >= alpha else \"No normal\"\n",
    "    decision_ks = \"Normal\" if p_ks >= alpha else \"No normal\"\n",
    "    \n",
    "    # Guardar resultado\n",
    "    normality_results.append({\n",
    "        \"Variable\": var,\n",
    "        \"n\": len(x),\n",
    "        \"SW_W\": W,\n",
    "        \"SW_p\": p_sw,\n",
    "        \"SW_decisi√≥n\": decision_sw,\n",
    "        \"KS_D\": D,\n",
    "        \"KS_p\": p_ks,\n",
    "        \"KS_decisi√≥n\": decision_ks\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Resultados de pruebas de normalidad:\")\n",
    "print(\"=\" * 100)\n",
    "for result in normality_results:\n",
    "    print(f\"\\n{result['Variable']}:\")\n",
    "    print(f\"  n={result['n']}\")\n",
    "    print(f\"  Shapiro-Wilk: W={result['SW_W']:.4f}, p={result['SW_p']:.4f} ‚Üí {result['SW_decisi√≥n']}\")\n",
    "    print(f\"  KS-Lilliefors: D={result['KS_D']:.4f}, p={result['KS_p']:.4f} ‚Üí {result['KS_decisi√≥n']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16a148",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 An√°lisis Bivariado\n",
    "\n",
    "**Estado**: ‚úÖ 100% completado - **COMPLETO**  \n",
    "**Actualizaci√≥n:** C√≥digo migrado completamente desde `1_check_data.ipynb`\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Preparaci√≥n de datos (drop de columnas de outliers y categ√≥ricas)\n",
    "- ‚úÖ Matriz de correlaci√≥n de Pearson calculada\n",
    "- ‚úÖ **Matriz de correlaci√≥n de Spearman calculada**\n",
    "- ‚úÖ Heatmap de correlaci√≥n Pearson generado\n",
    "- ‚úÖ **Identificaci√≥n autom√°tica de correlaciones fuertes (|r| > 0.7)**\n",
    "- ‚úÖ **Correlaciones separadas por grupo (GDM+ vs GDM-)**\n",
    "- ‚úÖ **Heatmaps individuales por grupo**\n",
    "- ‚úÖ **Heatmap de diferencias entre grupos**\n",
    "- ‚úÖ **Pairplot completo con visualizaci√≥n por grupo GDM**\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Scatterplots con regresi√≥n para pares clave (FPG vs HbA1c, Insulina vs HOMA-IR) - opcional\n",
    "- ‚è≥ Incluir ecuaci√≥n de regresi√≥n y R¬≤ en gr√°ficos - opcional\n",
    "- ‚è≥ Boxplots comparativos adicionales por grupo GDM - opcional\n",
    "- ‚è≥ Interpretaci√≥n cl√≠nica detallada de asociaciones encontradas\n",
    "- ‚è≥ Relacionar hallazgos con literatura sobre GDM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bf1b7",
   "metadata": {},
   "source": [
    "### Matriz de correlaci√≥n y heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Recordatorio de variables categ√≥ricas a excluir del an√°lisis\n",
    "# Utilidad: Clarificar qu√© variables no deben incluirse en correlaciones\n",
    "# Las correlaciones de Pearson/Spearman son para variables continuas\n",
    "print(\"üìù Recordatorio - Variables categ√≥ricas/binarias (excluidas de correlaciones):\")\n",
    "print(columns_to_ignore)\n",
    "print(f\"\\nEstas {len(columns_to_ignore)} variables ser√°n eliminadas junto con las de detecci√≥n de outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Verificar estructura del dataset filtrado antes del an√°lisis bivariado\n",
    "# Utilidad: Confirmar qu√© columnas est√°n disponibles y cu√°les deben eliminarse\n",
    "# para el an√°lisis de correlaciones (solo variables continuas)\n",
    "print(\"üîç INSPECCI√ìN PRE-AN√ÅLISIS BIVARIADO:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Dimensiones de df_filter: {df_filter.shape}\")\n",
    "print(f\"\\nüìã Columnas actuales en df_filter:\")\n",
    "print(df_filter.columns.tolist())\n",
    "print(f\"\\nüìä Total de columnas: {len(df_filter.columns)}\")\n",
    "print(f\"   - Variables originales: {len([c for c in df_filter.columns if not c.startswith('is_outlier') and c != 'vote_outlier'])}\")\n",
    "print(f\"   - Columnas de detecci√≥n de outliers: {len([c for c in df_filter.columns if c.startswith('is_outlier') or c == 'vote_outlier'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para an√°lisis bivariado: eliminar columnas de detecci√≥n de outliers\n",
    "df_filter_clean = df_filter.drop(columns=['is_outlier_by_IQR', 'is_outlier_by_IF_all', \n",
    "                                           'is_outlier_by_IF_just_values', 'is_outlier_by_IF_just_cat', \n",
    "                                           'vote_outlier', 'parity', 'family_history_t2d', 'previous_gdm',\n",
    "                                           'pcos', 'smoking_first_trimester', 'physical_activity_level'])\n",
    "\n",
    "print(\"‚úÖ Dataset limpio para an√°lisis bivariado creado\")\n",
    "print(f\"üìä Variables para correlaci√≥n: {df_filter_clean.shape[1] - 1} (excluyendo label_gdm)\")\n",
    "print(f\"Variables: {list(df_filter_clean.drop(columns=['label_gdm']).columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular correlaci√≥n de Pearson y Spearman\n",
    "df_corr_pearson = df_filter_clean.drop(columns=[\"label_gdm\"]).corr(method=\"pearson\")\n",
    "df_corr_spearman = df_filter_clean.drop(columns=[\"label_gdm\"]).corr(method=\"spearman\")\n",
    "\n",
    "print(\"‚úÖ Correlaciones calculadas:\")\n",
    "print(\"  - Pearson (lineal)\")\n",
    "print(\"  - Spearman (monot√≥nica)\")\n",
    "\n",
    "# Visualizar heatmap de Pearson\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(data=df_corr_pearson, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar_kws={'label': 'Correlaci√≥n de Pearson'})\n",
    "plt.title(\"Matriz de Correlaci√≥n de Pearson - Variables Continuas\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Correlaciones fuertes encontradas (|r| > 0.7):\")\n",
    "print(\"=\" * 50)\n",
    "# Identificar correlaciones fuertes\n",
    "strong_corr_found = False\n",
    "for i in range(len(df_corr_pearson.columns)):\n",
    "    for j in range(i+1, len(df_corr_pearson.columns)):\n",
    "        corr_value = df_corr_pearson.iloc[i, j]\n",
    "        if abs(corr_value) > 0.7:\n",
    "            print(f\"{df_corr_pearson.columns[i]} vs {df_corr_pearson.columns[j]}: r = {corr_value:.3f}\")\n",
    "            strong_corr_found = True\n",
    "\n",
    "if not strong_corr_found:\n",
    "    print(\"No se encontraron correlaciones > 0.7 (esperado en datos sint√©ticos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802da4ac",
   "metadata": {},
   "source": [
    "#### An√°lisis de correlaciones por grupo GDM\n",
    "\n",
    "Se calculan correlaciones separadas para pacientes con y sin GDM para identificar patrones diferenciados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ae927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlaciones separadas por grupo\n",
    "df_corr_pearson_pos = df_filter_clean[df_filter_clean[\"label_gdm\"] == 1].drop(columns=[\"label_gdm\"]).corr(method=\"pearson\")\n",
    "df_corr_pearson_neg = df_filter_clean[df_filter_clean[\"label_gdm\"] == 0].drop(columns=[\"label_gdm\"]).corr(method=\"pearson\")\n",
    "\n",
    "print(f\"‚úÖ Correlaciones por grupo calculadas:\")\n",
    "print(f\"  - GDM+ (positivo): {(df_filter_clean['label_gdm'] == 1).sum()} pacientes\")\n",
    "print(f\"  - GDM- (negativo): {(df_filter_clean['label_gdm'] == 0).sum()} pacientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap para grupo GDM+ (positivo)\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(data=df_corr_pearson_pos, annot=True, fmt=\".2f\", cmap=\"Reds\", \n",
    "            cbar_kws={'label': 'Correlaci√≥n de Pearson'})\n",
    "plt.title(\"Correlaci√≥n de Pearson - Pacientes con GDM (Positivo)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d756bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap para grupo GDM- (negativo)\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(data=df_corr_pearson_neg, annot=True, fmt=\".2f\", cmap=\"Greens\", \n",
    "            cbar_kws={'label': 'Correlaci√≥n de Pearson'})\n",
    "plt.title(\"Correlaci√≥n de Pearson - Pacientes sin GDM (Negativo)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de diferencias entre grupos (GDM- menos GDM+)\n",
    "plt.figure(figsize=(14, 12))\n",
    "df_corr_diff = df_corr_pearson_neg - df_corr_pearson_pos\n",
    "sns.heatmap(data=df_corr_diff, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0,\n",
    "            cbar_kws={'label': 'Diferencia de Correlaci√≥n (GDM- - GDM+)'})\n",
    "plt.title(\"Diferencias en Correlaci√≥n entre Grupos (GDM- - GDM+)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Mayores diferencias en correlaci√≥n entre grupos:\")\n",
    "print(\"=\" * 70)\n",
    "# Encontrar las mayores diferencias\n",
    "diff_values = []\n",
    "for i in range(len(df_corr_diff.columns)):\n",
    "    for j in range(i+1, len(df_corr_diff.columns)):\n",
    "        diff = df_corr_diff.iloc[i, j]\n",
    "        if abs(diff) > 0.2:  # Diferencias mayores a 0.2\n",
    "            diff_values.append((df_corr_diff.columns[i], df_corr_diff.columns[j], diff))\n",
    "\n",
    "if diff_values:\n",
    "    for var1, var2, diff in sorted(diff_values, key=lambda x: abs(x[2]), reverse=True)[:5]:\n",
    "        print(f\"{var1} vs {var2}: Œîr = {diff:.3f}\")\n",
    "else:\n",
    "    print(\"No se encontraron diferencias sustanciales (> 0.2) entre grupos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650f5ad",
   "metadata": {},
   "source": [
    "#### Pairplot: Relaciones entre todas las variables\n",
    "\n",
    "Visualizaci√≥n comprehensiva de las relaciones bivariadas entre todas las variables continuas, separadas por grupo GDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot completo con separaci√≥n por grupo GDM\n",
    "print(\"‚è≥ Generando pairplot (puede tardar unos segundos)...\")\n",
    "pairplot_fig = sns.pairplot(data=df_filter_clean, hue=\"label_gdm\", \n",
    "                             diag_kind=\"kde\", plot_kws={'alpha': 0.6},\n",
    "                             palette={0: \"green\", 1: \"red\"})\n",
    "pairplot_fig.fig.suptitle(\"Relaciones Bivariadas - Todas las Variables por Grupo GDM\", \n",
    "                          y=1.01, fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚úÖ Pairplot generado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a04ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n final: Verificaci√≥n del dataset limpio usado en an√°lisis bivariado\n",
    "# Utilidad: Confirmar que df_filter_clean contiene solo variables continuas + label_gdm\n",
    "# y que no hay valores faltantes que puedan afectar las correlaciones\n",
    "print(\"‚úÖ VERIFICACI√ìN FINAL DEL DATASET PARA AN√ÅLISIS BIVARIADO:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä Dimensiones de df_filter_clean: {df_filter_clean.shape}\")\n",
    "print(f\"   Registros: {df_filter_clean.shape[0]} (despu√©s de filtrar outliers)\")\n",
    "print(f\"   Variables: {df_filter_clean.shape[1]} (solo continuas + label_gdm)\")\n",
    "print(f\"\\nüìã Variables incluidas:\")\n",
    "print(df_filter_clean.columns.tolist())\n",
    "print(f\"\\nüîç Valores faltantes por variable:\")\n",
    "missing = df_filter_clean.isna().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"   ‚úì No hay valores faltantes en el dataset limpio\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "print(f\"\\n‚úì Dataset listo para an√°lisis de correlaciones y visualizaciones bivariadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce017ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.6 Interpretaci√≥n Cl√≠nica y Conclusiones\n",
    "\n",
    "**Estado**: üî¥ 0% completado - **CR√çTICO**  \n",
    "**Pendiente**: Toda la secci√≥n de conclusiones\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ S√≠ntesis de variables con distribuci√≥n no normal y consecuencias\n",
    "- ‚è≥ Resumen de diferencias significativas entre grupos (GDM vs No-GDM)\n",
    "- ‚è≥ Destacar direcci√≥n de diferencias (qu√© grupo tiene valores m√°s altos/bajos)\n",
    "- ‚è≥ Listar correlaciones cl√≠nicamente relevantes y su significado\n",
    "- ‚è≥ Discutir posibles relaciones causales vs correlaci√≥n espuria\n",
    "- ‚è≥ Comentar sobre datos faltantes y su posible impacto\n",
    "- ‚è≥ Discutir sesgos potenciales en la muestra\n",
    "- ‚è≥ Mencionar variables confusoras no controladas\n",
    "- ‚è≥ Proponer an√°lisis multivariado (regresi√≥n log√≠stica)\n",
    "- ‚è≥ Sugerir validaci√≥n cruzada de modelos predictivos\n",
    "- ‚è≥ Recomendar estudios adicionales\n",
    "\n",
    "---\n",
    "\n",
    "### Secci√≥n a completar\n",
    "\n",
    "**Estructura sugerida para las conclusiones:**\n",
    "\n",
    "1. **Resumen de hallazgos principales**\n",
    "   - Variables no normales y sus implicancias\n",
    "   - Diferencias significativas entre grupos\n",
    "   - Correlaciones relevantes encontradas\n",
    "\n",
    "2. **Interpretaci√≥n cl√≠nica**\n",
    "   - Significado de las diferencias entre GDM vs No-GDM\n",
    "   - Relevancia de las correlaciones para el diagn√≥stico/pron√≥stico\n",
    "   - Comparaci√≥n con rangos cl√≠nicos de referencia\n",
    "\n",
    "3. **Limitaciones del estudio**\n",
    "   - Impacto de datos faltantes\n",
    "   - Sesgos y variables confusoras\n",
    "   - Naturaleza del dataset sint√©tico\n",
    "\n",
    "4. **Pr√≥ximos pasos**\n",
    "   - An√°lisis multivariado recomendado\n",
    "   - Validaci√≥n de modelos predictivos\n",
    "   - Estudios complementarios necesarios\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfa837",
   "metadata": {},
   "source": [
    "# 3. Entregables y Archivos Adjuntos\n",
    "\n",
    "## Archivos incluidos en la entrega\n",
    "\n",
    "Este trabajo pr√°ctico incluye los siguientes archivos que deben ser entregados en un archivo comprimido (`.tar.gz` o `.zip`):\n",
    "\n",
    "### Archivos principales\n",
    "\n",
    "1. **`Entregable.ipynb`** (este documento)\n",
    "   - Notebook principal con todo el an√°lisis organizado por secciones\n",
    "   - Incluye c√≥digo, visualizaciones e interpretaciones\n",
    "   - Indicadores de progreso por secci√≥n\n",
    "\n",
    "2. **`gdm_first_trimester_ml_dataset.csv`**\n",
    "   - Dataset original con los datos cl√≠nicos\n",
    "   - N ‚âà 1500 registros de pacientes embarazadas\n",
    "   - Variables cl√≠nicas, bioqu√≠micas y de estilo de vida\n",
    "\n",
    "3. **`gdm_first_trimester_ml_dataset_metadata.json`**\n",
    "   - Metadata del dataset\n",
    "   - Descripci√≥n de variables y tipos de datos\n",
    "   - Informaci√≥n sobre valores faltantes y rangos esperados\n",
    "\n",
    "4. **`auxiliar_functions.py`**\n",
    "   - Funciones auxiliares implementadas para el an√°lisis\n",
    "   - Incluye funciones para:\n",
    "     - C√°lculo de intervalos de confianza (media, varianza, desviaci√≥n)\n",
    "     - Detecci√≥n de outliers\n",
    "     - Generaci√≥n de res√∫menes de conteos\n",
    "     - Otras utilidades\n",
    "\n",
    "### Archivos de referencia y documentaci√≥n\n",
    "\n",
    "5. **`INSTRUCCIONES.md`**\n",
    "   - Gu√≠a pr√°ctica original del profesor\n",
    "   - Descripci√≥n de actividades y entregables\n",
    "   - Criterios de evaluaci√≥n\n",
    "\n",
    "6. **`TASKS.md` / `TASK2.md`**\n",
    "   - Lista detallada de tareas pendientes\n",
    "   - Organizaci√≥n por prioridad (`TASKS.md`) y por secci√≥n (`TASK2.md`)\n",
    "   - Indicadores de progreso y estimaciones de tiempo\n",
    "\n",
    "7. **`README.md` (en carpeta `__pycache__/`)**\n",
    "   - Evaluaci√≥n de estado del progreso\n",
    "   - Retroalimentaci√≥n detallada por secci√≥n\n",
    "   - Porcentajes de avance y correcci√≥n\n",
    "\n",
    "8. **`.gitignore`**\n",
    "   - Configuraci√≥n de archivos ignorados por Git\n",
    "   - Incluye: `__pycache__/`, `*.pyc`, entornos virtuales, etc.\n",
    "\n",
    "### Archivos de trabajo (prototipos)\n",
    "\n",
    "9. **`1_check_data.ipynb`**\n",
    "   - Prototipo inicial del an√°lisis\n",
    "   - Contiene desarrollo del c√≥digo que luego se organiz√≥ en `Entregable.ipynb`\n",
    "\n",
    "10. **`check_data.ipynb`**\n",
    "    - Versi√≥n preliminar del prototipo (obsoleta)\n",
    "\n",
    "---\n",
    "\n",
    "## Herramientas utilizadas\n",
    "\n",
    "### Software y entorno\n",
    "\n",
    "- **Python 3.x**\n",
    "- **Jupyter Notebook / JupyterLab**\n",
    "- **Git** (control de versiones)\n",
    "\n",
    "### Librer√≠as principales\n",
    "\n",
    "- **pandas**: Manipulaci√≥n y an√°lisis de datos\n",
    "- **numpy**: Operaciones num√©ricas y √°lgebra lineal\n",
    "- **matplotlib**: Visualizaci√≥n b√°sica\n",
    "- **seaborn**: Visualizaci√≥n estad√≠stica avanzada\n",
    "- **scipy.stats**: Pruebas estad√≠sticas (Shapiro-Wilk, KS, t-test, Mann-Whitney, Levene, etc.)\n",
    "- **sklearn.ensemble.IsolationForest**: Detecci√≥n de anomal√≠as/outliers\n",
    "\n",
    "### Herramientas de IA (si aplica)\n",
    "\n",
    "**[Indicar aqu√≠ si se us√≥ ChatGPT, GitHub Copilot u otra herramienta de IA, especificando para qu√© tareas]**\n",
    "\n",
    "Ejemplo:\n",
    "> Se utiliz√≥ GitHub Copilot para:\n",
    "> - Generaci√≥n de c√≥digo auxiliar para funciones estad√≠sticas\n",
    "> - Sugerencias de visualizaci√≥n con seaborn\n",
    "> - Redacci√≥n de comentarios y documentaci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "## Instrucciones de ejecuci√≥n\n",
    "\n",
    "### Requisitos previos\n",
    "\n",
    "1. Instalar Python 3.8 o superior\n",
    "2. Instalar las librer√≠as necesarias:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn scipy scikit-learn\n",
    "```\n",
    "\n",
    "### Ejecuci√≥n del notebook\n",
    "\n",
    "1. Abrir `Entregable.ipynb` en Jupyter Notebook/Lab\n",
    "2. Asegurar que `gdm_first_trimester_ml_dataset.csv` y `auxiliar_functions.py` est√°n en el mismo directorio\n",
    "3. Ejecutar las celdas secuencialmente desde el inicio\n",
    "\n",
    "### Notas importantes\n",
    "\n",
    "- Algunas celdas en secciones incompletas (üî¥) pueden fallar si no se han ejecutado celdas previas necesarias\n",
    "- El dataset filtrado `df_filter` se genera en la secci√≥n 2.1 y se usa en secciones posteriores\n",
    "- Los resultados de normalidad (secci√≥n 2.4) deben usarse para justificar elecciones de tests en secci√≥n 2.3\n",
    "\n",
    "---\n",
    "\n",
    "## Informaci√≥n de contacto\n",
    "\n",
    "**Estudiante(s):** [Completar nombre(s)]  \n",
    "**Correo:** [Completar correo(s)]  \n",
    "**Fecha de entrega:** 15 de noviembre de 2025  \n",
    "**Profesor:** David Medina Ortiz  \n",
    "**Correo del profesor:** david.medina@umag.cl\n",
    "\n",
    "---\n",
    "\n",
    "**Fin del documento**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
