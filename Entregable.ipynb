{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5f3695",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos: Caracterizaci√≥n Estad√≠stica del Riesgo de Diabetes Gestacional (GDM)\n",
    "\n",
    "**Universidad de Magallanes**  \n",
    "**Facultad de Ingenier√≠a, Departamento de Ingenier√≠a en Computaci√≥n**  \n",
    "**Asignatura:** Matem√°tica para Ciencias de la Computaci√≥n  \n",
    "**Profesor:** David Medina Ortiz  \n",
    "\n",
    "---\n",
    "\n",
    "**Equipo:** Alma de Litio  \n",
    "**Estudiante(s):** Pablo G√≥mez (L√≠der), Emmanuel Vel√°squez, Diego Vidal  \n",
    "**Fecha de entrega:** 12 de noviembre de 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## Resumen Ejecutivo\n",
    "\n",
    "Este informe presenta un an√°lisis exploratorio exhaustivo de un dataset sint√©tico que simula informaci√≥n cl√≠nica del primer trimestre del embarazo, con el objetivo de caracterizar estad√≠sticamente los datos y explorar asociaciones entre variables cl√≠nicas y el riesgo de desarrollar diabetes gestacional (GDM). El an√°lisis incluye estad√≠stica descriptiva, identificaci√≥n de valores at√≠picos mediante m√∫ltiples m√©todos (IQR e Isolation Forest), visualizaciones comparativas entre grupos, an√°lisis de correlaciones, pruebas de normalidad, pruebas de hip√≥tesis e intervalos de confianza.\n",
    "\n",
    "**Resultados principales:**\n",
    "- Dataset de 1500 registros con 17% de casos positivos de GDM\n",
    "- Identificaci√≥n exitosa de outliers mediante sistema de votaci√≥n (4 m√©todos)\n",
    "- An√°lisis bivariado completo con correlaciones de Pearson y Spearman por grupo\n",
    "- Evaluaci√≥n de normalidad para todas las variables continuas\n",
    "- Comparaciones estad√≠sticas entre grupos GDM+ y GDM-\n",
    "\n",
    "---\n",
    "\n",
    "## Tabla de Progreso Global\n",
    "\n",
    "*Nota interna del equipo: Valores actualizados seg√∫n an√°lisis exhaustivo vs INSTRUCCIONES.md (12/nov/2025)*\n",
    "\n",
    "| Secci√≥n | T√≠tulo | Progreso Real | Estado | Requisitos Faltantes |\n",
    "|---------|--------|---------------|--------|---------------------|\n",
    "| 1 | Descripci√≥n General del Dataset | 100% | ‚úÖ | Ninguno |\n",
    "| 2.1 | An√°lisis Exploratorio de Datos (EDA) | 100% | ‚úÖ | Ninguno |\n",
    "| 2.2 | Intervalos de Confianza | 75% | üü° | Interpretaci√≥n cl√≠nica |\n",
    "| 2.3 | Pruebas de Hip√≥tesis | 18% | üî¥ | Comparaciones clave, proporciones, interpretaci√≥n |\n",
    "| 2.4 | Evaluaci√≥n de Normalidad | 90% | üü¢ | Discusi√≥n de impacto en pruebas |\n",
    "| 2.5 | An√°lisis Bivariado | 95% | üü¢ | Discusi√≥n de asociaciones relevantes |\n",
    "| 2.6 | Interpretaci√≥n Cl√≠nica y Conclusiones | 0% | üî¥ | TODO: Secci√≥n completa |\n",
    "| 3 | Entregables y Archivos | 100% | ‚úÖ | Ninguno |\n",
    "| **GLOBAL** | **Progreso Total** | **64%** | üü° | **Prioridad: 2.3, 2.6, 2.2** |\n",
    "\n",
    "**An√°lisis de brecha:** Faltan ~27 puntos porcentuales para cumplir requisitos m√≠nimos de INSTRUCCIONES.md  \n",
    "**Acciones cr√≠ticas:** Completar pruebas de hip√≥tesis (2.3), redactar conclusiones (2.6), agregar interpretaciones cl√≠nicas (2.2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64237ba6",
   "metadata": {},
   "source": [
    "# 1. Descripci√≥n General del Dataset\n",
    "\n",
    "## 1.1 Contexto del Estudio\n",
    "\n",
    "Este trabajo utiliza un **dataset sint√©tico** que simula informaci√≥n cl√≠nica recopilada durante el **primer trimestre del embarazo**, dise√±ado espec√≠ficamente para el estudio de factores asociados al desarrollo de **diabetes gestacional (GDM)**. El dataset representa un escenario realista de datos cl√≠nicos con caracter√≠sticas propias de la pr√°ctica m√©dica, incluyendo valores faltantes y datos at√≠picos.\n",
    "\n",
    "La diabetes gestacional es una condici√≥n de hiperglucemia que se desarrolla durante el embarazo y puede tener consecuencias significativas tanto para la madre como para el feto. La identificaci√≥n temprana de factores de riesgo en el primer trimestre permitir√≠a intervenciones preventivas oportunas.\n",
    "\n",
    "## 1.2 Caracter√≠sticas del Dataset\n",
    "\n",
    "### Dimensiones y estructura\n",
    "- **Tama√±o muestral (N)**: Aproximadamente 1500 registros de pacientes embarazadas\n",
    "- **Variables totales**: 25 variables (21 predictoras + 1 objetivo + 3 derivadas)\n",
    "- **Tipos de variables**: Continuas, discretas y categ√≥ricas binarias\n",
    "\n",
    "### Variables incluidas\n",
    "\n",
    "#### Variables demogr√°ficas y antropom√©tricas:\n",
    "- `age_years`: Edad de la paciente en a√±os\n",
    "- `bmi_prepreg_kg_m2`: √çndice de masa corporal pregestacional (kg/m¬≤)\n",
    "\n",
    "#### Variables hemodin√°micas:\n",
    "- `systolic_bp_mmHg`: Presi√≥n arterial sist√≥lica (mmHg)\n",
    "- `diastolic_bp_mmHg`: Presi√≥n arterial diast√≥lica (mmHg)\n",
    "- `map_mmHg`: Presi√≥n arterial media (mmHg)\n",
    "\n",
    "#### Variables metab√≥licas y bioqu√≠micas:\n",
    "- `fpg_mmol_l`: Glucosa plasm√°tica en ayunas (mmol/L)\n",
    "- `hba1c_percent`: Hemoglobina glicosilada (%)\n",
    "- `insulin_uIU_ml`: Insulina s√©rica (ŒºIU/mL)\n",
    "- `homa_ir`: √çndice HOMA-IR (resistencia a la insulina)\n",
    "- `triglycerides_mmol_l`: Triglic√©ridos s√©ricos (mmol/L)\n",
    "- `hdl_mmol_l`: Colesterol HDL (mmol/L)\n",
    "\n",
    "#### Variables obst√©tricas y de antecedentes:\n",
    "- `gestational_weeks`: Semanas de gestaci√≥n al momento de la medici√≥n\n",
    "- `parity`: Paridad (n√∫mero de embarazos previos)\n",
    "- `previous_gdm`: Antecedente de diabetes gestacional previa (0/1)\n",
    "- `family_history_t2d`: Antecedentes familiares de diabetes tipo 2 (0/1)\n",
    "\n",
    "#### Variables de condiciones preexistentes:\n",
    "- `pcos`: Diagn√≥stico de s√≠ndrome de ovario poliqu√≠stico (0/1)\n",
    "\n",
    "#### Variables de estilo de vida:\n",
    "- `smoking_first_trimester`: Tabaquismo durante el primer trimestre (0/1)\n",
    "- `physical_activity_level`: Nivel de actividad f√≠sica (escala ordinal)\n",
    "- `diet_score_0_100`: Puntuaci√≥n de calidad diet√©tica (0-100)\n",
    "\n",
    "#### Variable objetivo:\n",
    "- `label_gdm`: Diagn√≥stico de diabetes gestacional (0 = No GDM, 1 = GDM)\n",
    "\n",
    "## 1.3 Caracter√≠sticas Especiales del Dataset\n",
    "\n",
    "### Datos faltantes (Missing Data)\n",
    "El dataset presenta valores faltantes con dos patrones principales:\n",
    "- **MCAR (Missing Completely At Random)**: Ausencia de datos sin relaci√≥n con otras variables\n",
    "- **MAR (Missing At Random)**: Valores faltantes relacionados con otras variables observadas\n",
    "\n",
    "### Valores at√≠picos (Outliers)\n",
    "Se observa la presencia de valores extremos en diversas variables que requieren:\n",
    "- Identificaci√≥n sistem√°tica mediante m√∫ltiples m√©todos\n",
    "- Evaluaci√≥n de su naturaleza (error vs variabilidad biol√≥gica)\n",
    "- Tratamiento apropiado antes de an√°lisis inferenciales\n",
    "\n",
    "### Desbalance de clases\n",
    "- **Proporci√≥n de casos positivos**: Aproximadamente 17% (prevalencia realista de GDM)\n",
    "- **Proporci√≥n de casos negativos**: 83%\n",
    "- Este desbalance refleja la prevalencia real de GDM en poblaciones de riesgo moderado\n",
    "\n",
    "## 1.4 Objetivos del An√°lisis\n",
    "\n",
    "### Objetivo general\n",
    "Realizar un an√°lisis exploratorio exhaustivo que permita caracterizar estad√≠sticamente el dataset y comprender las relaciones entre variables cl√≠nicas y el riesgo de diabetes gestacional.\n",
    "\n",
    "### Objetivos espec√≠ficos\n",
    "1. **Caracterizar la distribuci√≥n** de todas las variables del dataset mediante estad√≠stica descriptiva\n",
    "2. **Identificar y tratar valores at√≠picos** utilizando m√©todos robustos y complementarios\n",
    "3. **Detectar patrones y asociaciones** entre variables mediante an√°lisis bivariado\n",
    "4. **Comparar grupos** (GDM+ vs GDM-) mediante pruebas de hip√≥tesis apropiadas\n",
    "5. **Evaluar supuestos estad√≠sticos** (normalidad, homocedasticidad) para justificar elecci√≥n de tests\n",
    "6. **Calcular intervalos de confianza** para estimar par√°metros poblacionales\n",
    "7. **Generar insights cl√≠nicos** relevantes para la comprensi√≥n del riesgo de GDM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0aa53b",
   "metadata": {},
   "source": [
    "# 2. Metodolog√≠a y Resultados\n",
    "\n",
    "Esta secci√≥n presenta el desarrollo metodol√≥gico y los resultados obtenidos, organizado seg√∫n las actividades especificadas en la gu√≠a pr√°ctica. Cada subsecci√≥n incluye la justificaci√≥n metodol√≥gica, el c√≥digo implementado, los resultados obtenidos y su interpretaci√≥n preliminar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ad0a9",
   "metadata": {},
   "source": [
    "## 2.1 An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "### Introducci√≥n\n",
    "\n",
    "El an√°lisis exploratorio de datos constituye la primera fase fundamental de cualquier estudio estad√≠stico. En este apartado se examina la estructura del dataset, se caracterizan las distribuciones de las variables, se identifican valores at√≠picos mediante m√∫ltiples m√©todos complementarios, y se generan visualizaciones comparativas entre grupos.\n",
    "\n",
    "### Metodolog√≠a\n",
    "\n",
    "La estrategia de an√°lisis exploratorio incluye:\n",
    "\n",
    "1. **Carga y verificaci√≥n inicial**: Inspecci√≥n de dimensiones, tipos de datos y primeros registros\n",
    "2. **An√°lisis de datos faltantes**: Cuantificaci√≥n y caracterizaci√≥n de valores nulos\n",
    "3. **Estad√≠stica descriptiva**: C√°lculo de medidas de tendencia central, dispersi√≥n y posici√≥n\n",
    "4. **Detecci√≥n de outliers multicriterio**:\n",
    "   - M√©todo IQR (rango intercuart√≠lico)\n",
    "   - Isolation Forest sobre variables categ√≥ricas\n",
    "   - Isolation Forest sobre variables continuas\n",
    "   - Isolation Forest sobre todas las variables\n",
    "5. **Sistema de votaci√≥n**: Clasificaci√≥n de outliers seg√∫n n√∫mero de m√©todos concordantes\n",
    "6. **Filtrado de datos**: Remoci√≥n de outliers extremos (identificados por ‚â•3 m√©todos)\n",
    "7. **Visualizaci√≥n comparativa**: Generaci√≥n de histogramas, boxplots y violinplots por grupo GDM\n",
    "\n",
    "### Justificaci√≥n metodol√≥gica\n",
    "\n",
    "- **M√∫ltiples m√©todos de detecci√≥n**: Se implementan 4 t√©cnicas complementarias para aumentar la robustez en la identificaci√≥n de valores at√≠picos, reduciendo falsos positivos\n",
    "- **Sistema de votaci√≥n**: Permite clasificar outliers seg√∫n severidad, facilitando decisiones de filtrado conservadoras\n",
    "- **Criterio de exclusi√≥n (‚â•3 votos)**: Elimina solo casos extremos, preservando variabilidad biol√≥gica genuina\n",
    "- **Isolation Forest**: Algoritmo no param√©trico efectivo para detectar anomal√≠as en espacios multidimensionales\n",
    "\n",
    "### Estado de completitud\n",
    "\n",
    "**‚úÖ Completado al 100%**\n",
    "\n",
    "#### Tareas realizadas:\n",
    "- ‚úÖ Carga de datos y verificaci√≥n de dimensiones\n",
    "- ‚úÖ An√°lisis de tipos de datos\n",
    "- ‚úÖ Detecci√≥n exhaustiva de valores faltantes\n",
    "- ‚úÖ Estad√≠stica descriptiva completa (media, mediana, IQR, percentiles)\n",
    "- ‚úÖ Detecci√≥n de outliers por IQR (m√©todo `check_is_outlier`)\n",
    "- ‚úÖ Detecci√≥n con Isolation Forest (3 variantes: categ√≥ricas, continuas, todas)\n",
    "- ‚úÖ Sistema de votaci√≥n de outliers (4 m√©todos)\n",
    "- ‚úÖ Filtrado de outliers (criterio: vote_outlier < 3)\n",
    "- ‚úÖ Creaci√≥n de `df_filter` (dataset limpio para an√°lisis posteriores)\n",
    "- ‚úÖ Visualizaciones completas por grupo GDM:\n",
    "  - Histogramas con KDE superpuesto\n",
    "  - Boxplots comparativos\n",
    "  - Violinplots con densidad\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585aa278",
   "metadata": {},
   "source": [
    "### 2.1.1 Importaci√≥n de Librer√≠as\n",
    "\n",
    "Se cargan las librer√≠as necesarias para el an√°lisis estad√≠stico, manipulaci√≥n de datos y visualizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from auxiliar_functions import *\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9c3e4",
   "metadata": {},
   "source": [
    "### 2.1.2 Carga y Exploraci√≥n Inicial del Dataset\n",
    "\n",
    "Se realiza la carga del archivo CSV y se inspeccionan las primeras observaciones, dimensiones y estructura general de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f52dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "df_data = pd.read_csv(\"gdm_first_trimester_ml_dataset.csv\")\n",
    "\n",
    "# Primeras filas\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "print(f\"Dimensiones: {df_data.shape}\")\n",
    "print(f\"Total de registros: {df_data.shape[0]}\")\n",
    "print(f\"Total de variables: {df_data.shape[1]}\")\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de la variable objetivo\n",
    "print(\"Distribuci√≥n de GDM:\")\n",
    "print(df_data[\"label_gdm\"].value_counts())\n",
    "print(f\"\\nProporci√≥n de casos positivos: {df_data['label_gdm'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos\n",
    "print(\"Tipos de datos por variable:\")\n",
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n de variable categ√≥rica: PCOS\n",
    "# Utilidad: Verificar cu√°ntos valores √∫nicos tiene esta variable binaria (0/1)\n",
    "# Esto confirma que PCOS es efectivamente una variable dicot√≥mica sin valores an√≥malos\n",
    "print(\"üîç Exploraci√≥n de la variable PCOS (S√≠ndrome de Ovario Poliqu√≠stico):\")\n",
    "print(f\"Valores √∫nicos: {df_data['pcos'].unique()}\")\n",
    "print(f\"N√∫mero de valores √∫nicos: {df_data['pcos'].unique().shape[0]}\")\n",
    "print(\"\\nDistribuci√≥n de PCOS:\")\n",
    "print(df_data[\"pcos\"].value_counts())\n",
    "print(f\"\\nüìä Proporci√≥n de pacientes con PCOS: {df_data['pcos'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d8bb4",
   "metadata": {},
   "source": [
    "### 2.1.3 An√°lisis de Valores Faltantes\n",
    "\n",
    "Se cuantifican los valores faltantes (NaN) por variable y se genera un resumen agregado para identificar patrones de datos ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls = df_data.isna().astype(int)\n",
    "df_summary_null = generate_df_counts(df_nulls, columns_name=[\"descriptor\", \"count_Nulls\", \"count_Falses\"])\n",
    "print(\"Resumen de valores faltantes:\")\n",
    "df_summary_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n detallada: Visualizar matriz completa de valores faltantes\n",
    "# Utilidad: Permite inspeccionar visualmente patrones de datos faltantes por registro\n",
    "# Cada fila representa un paciente, cada columna una variable (1=faltante, 0=presente)\n",
    "print(\"üìã Primeras 10 filas de la matriz de valores faltantes:\")\n",
    "print(\"(1 = dato faltante, 0 = dato presente)\\n\")\n",
    "df_nulls.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27535ff4",
   "metadata": {},
   "source": [
    "### 2.1.4 Estad√≠stica Descriptiva\n",
    "\n",
    "Se calculan medidas de tendencia central, dispersi√≥n y posici√≥n para todas las variables continuas. Se identifican variables categ√≥ricas/binarias que deben excluirse del an√°lisis descriptivo de variables continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_ignore = [\n",
    "    \"parity\", \n",
    "    \"family_history_t2d\",\n",
    "    \"previous_gdm\",\n",
    "    \"pcos\", \n",
    "    \"smoking_first_trimester\",\n",
    "    \"label_gdm\",\n",
    "    \"physical_activity_level\"\n",
    "]\n",
    "\n",
    "print(\"Variables categ√≥ricas/binarias a excluir del an√°lisis descriptivo:\")\n",
    "print(columns_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b36d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠stica descriptiva para todas las variables\n",
    "print(\"Estad√≠sticas descriptivas del dataset completo:\")\n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb410c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_descriptors = []\n",
    "\n",
    "for column in df_data.columns:\n",
    "    if column not in columns_to_ignore:\n",
    "        descriptive_values = df_data[column].describe()\n",
    "\n",
    "        IQR = descriptive_values[\"75%\"] - descriptive_values[\"25%\"]\n",
    "        min_value, max_value = get_range_outlier(\n",
    "            descriptive_values[\"25%\"], \n",
    "            descriptive_values[\"75%\"], \n",
    "            IQR)\n",
    "\n",
    "        row = {\n",
    "            \"descriptor\" : column,\n",
    "            \"mean\":descriptive_values[\"mean\"],\n",
    "            \"std\" :descriptive_values[\"std\"],\n",
    "            \"median\" : descriptive_values[\"50%\"],\n",
    "            \"IQR\" : IQR,\n",
    "            \"25%\" : descriptive_values[\"25%\"],\n",
    "            \"75%\" :descriptive_values[\"75%\"],\n",
    "            \"min_value_for_outlier\" : min_value,\n",
    "            \"max_value_for_outlier\" : max_value\n",
    "\n",
    "        }\n",
    "        statistical_descriptors.append(row)\n",
    "\n",
    "df_statistical = pd.DataFrame(statistical_descriptors)\n",
    "print(\"Estad√≠sticas descriptivas con IQR y umbrales para outliers:\")\n",
    "df_statistical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b06d9",
   "metadata": {},
   "source": [
    "### 2.1.5 Detecci√≥n de Valores At√≠picos (Outliers)\n",
    "\n",
    "Se implementa un sistema robusto de detecci√≥n de outliers mediante 4 m√©todos complementarios: IQR, Isolation Forest sobre variables categ√≥ricas, Isolation Forest sobre variables continuas, e Isolation Forest sobre todas las variables. Se utiliza un sistema de votaci√≥n para clasificar la severidad de los casos at√≠picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecci√≥n de outliers por m√©todo IQR\n",
    "df_outliers = pd.DataFrame()\n",
    "\n",
    "for column in df_data.columns:\n",
    "    if column not in columns_to_ignore:\n",
    "        \n",
    "        df_filter = df_statistical[df_statistical[\"descriptor\"] == column]\n",
    "        df_filter.reset_index(inplace=True)\n",
    "\n",
    "        min_value, max_value = df_filter[\"min_value_for_outlier\"][0], df_filter[\"max_value_for_outlier\"][0]\n",
    "\n",
    "        df_outliers[column] = df_data[column].apply(lambda x: check_is_outlier(x, min_value, max_value))\n",
    "\n",
    "print(\"Detecci√≥n de outliers por IQR completada\")\n",
    "print(f\"Dimensiones de df_outliers: {df_outliers.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a enteros y generar resumen\n",
    "df_outliers = df_outliers.astype(int)\n",
    "df_summary_outlier = generate_df_counts(df_outliers, columns_name=[\"descriptor\", \"count_Outlier\", \"count_NotOutlier\"])\n",
    "print(\"\\nResumen de outliers detectados por IQR:\")\n",
    "df_summary_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b65685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columna con conteo de outliers por fila\n",
    "df_outliers[\"outlier_by_IQR\"] = df_outliers.sum(axis=1)\n",
    "print(\"\\nDistribuci√≥n de n√∫mero de outliers por registro:\")\n",
    "print(df_outliers[\"outlier_by_IQR\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da691f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n detallada: Ejemplo de detecci√≥n en una variable espec√≠fica\n",
    "# Utilidad: Verificar la correcta aplicaci√≥n del m√©todo IQR en una variable clave\n",
    "print(\"üî¨ Ejemplo de detecci√≥n en triglic√©ridos:\")\n",
    "print(\"Distribuci√≥n de outliers (0=normal, 1=outlier):\")\n",
    "print(df_outliers[\"triglycerides_mmol_l\"].value_counts())\n",
    "print(f\"\\n‚ö†Ô∏è  Registros con triglic√©ridos at√≠picos: {df_outliers['triglycerides_mmol_l'].sum()}\")\n",
    "print(f\"‚úì Registros con triglic√©ridos normales: {(df_outliers['triglycerides_mmol_l'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af26337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Verificar estructura del dataframe de outliers\n",
    "# Utilidad: Confirmar que todas las variables continuas est√°n incluidas en el an√°lisis\n",
    "print(\"üìã Columnas incluidas en la detecci√≥n de outliers:\")\n",
    "print(df_outliers.columns.tolist())\n",
    "print(f\"\\nüìä Total de variables analizadas: {len(df_outliers.columns) - 1}\")  # -1 por outlier_by_IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fff822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n espec√≠fica: Casos extremos de paridad\n",
    "# Utilidad: Identificar valores poco comunes que podr√≠an ser outliers por s√≠ mismos\n",
    "# La paridad alta (‚â•5 embarazos) es cl√≠nicamente relevante para riesgo de GDM\n",
    "print(\"\\nüî¨ An√°lisis de casos extremos de paridad:\")\n",
    "paridad_extrema = df_data[df_data[\"parity\"] == 5]\n",
    "print(f\"Registros con paridad = 5: {len(paridad_extrema)}\")\n",
    "if len(paridad_extrema) > 0:\n",
    "    print(\"\\nPrimeros registros con paridad extrema:\")\n",
    "    print(paridad_extrema[[\"parity\", \"age_years\", \"bmi_prepreg_kg_m2\", \"label_gdm\"]].head())\n",
    "else:\n",
    "    print(\"No hay registros con paridad = 5 en el dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: An√°lisis de distribuci√≥n de todas las variables categ√≥ricas\n",
    "# Utilidad: Entender el balance de clases en variables binarias/categ√≥ricas\n",
    "# Esto es cr√≠tico antes de aplicar Isolation Forest para detectar combinaciones an√≥malas\n",
    "print(\"üìä DISTRIBUCI√ìN DE VARIABLES CATEG√ìRICAS/BINARIAS\")\n",
    "print(\"=\" * 70)\n",
    "for column in columns_to_ignore:\n",
    "    print(f\"\\nüîπ {column}:\")\n",
    "    print(df_data[column].value_counts().sort_index())\n",
    "    if column != \"label_gdm\":  # No calcular proporci√≥n para la etiqueta objetivo\n",
    "        try:\n",
    "            prop = df_data[column].mean()\n",
    "            print(f\"   Proporci√≥n de casos positivos: {prop:.2%}\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db925e46",
   "metadata": {},
   "source": [
    "#### 2.1.5.1 Exploraci√≥n de Variables Categ√≥ricas\n",
    "\n",
    "Antes de aplicar Isolation Forest, se examinan las distribuciones de las variables categ√≥ricas/binarias para comprender sus balances de clase y posibles combinaciones an√≥malas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734913c7",
   "metadata": {},
   "source": [
    "#### 2.1.5.2 Detecci√≥n con Isolation Forest\n",
    "\n",
    "**Isolation Forest** es un algoritmo de aprendizaje no supervisado que identifica anomal√≠as aislando observaciones mediante particiones aleatorias. Se aplican 3 estrategias complementarias:\n",
    "\n",
    "1. **Solo variables categ√≥ricas**: Detecta combinaciones inusuales de factores de riesgo\n",
    "2. **Solo variables continuas**: Identifica valores extremos en mediciones cl√≠nicas\n",
    "3. **Todas las variables**: Enfoque integral combinando ambos tipos de informaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Isolation Forest sobre variables categ√≥ricas\n",
    "data_categorical = df_data[columns_to_ignore]\n",
    "data_categorical = data_categorical.drop(columns=[\"label_gdm\"])\n",
    "\n",
    "isolation_instance = IsolationForest(random_state=42)\n",
    "isolation_instance.fit(data_categorical)\n",
    "data_categorical[\"is_isolated\"] = isolation_instance.predict(data_categorical)\n",
    "\n",
    "print(\"Isolation Forest - Solo categ√≥ricas:\")\n",
    "print(data_categorical[\"is_isolated\"].value_counts())\n",
    "print(f\"Outliers detectados: {(data_categorical['is_isolated'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Visualizar resultados del Isolation Forest en categ√≥ricas\n",
    "# Utilidad: Verificar qu√© combinaciones de factores de riesgo son consideradas an√≥malas\n",
    "# Permite identificar perfiles de pacientes con combinaciones inusuales de caracter√≠sticas\n",
    "print(\"üìã Primeras 10 filas con predicci√≥n de anomal√≠a (categ√≥ricas):\")\n",
    "print(\"Valores: 1 = normal, -1 = outlier/anomal√≠a\\n\")\n",
    "data_categorical.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Isolation Forest sobre solo valores continuos\n",
    "df_values = df_data.drop(columns=columns_to_ignore)\n",
    "\n",
    "isolation_instance = IsolationForest(random_state=42)\n",
    "isolation_instance.fit(df_values)\n",
    "df_values[\"is_isolated\"] = isolation_instance.predict(df_values)\n",
    "\n",
    "print(\"\\nIsolation Forest - Solo continuas:\")\n",
    "print(df_values[\"is_isolated\"].value_counts())\n",
    "print(f\"Outliers detectados: {(df_values['is_isolated'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Isolation Forest sobre todas las variables (excepto label_gdm)\n",
    "df_values_cat = df_data.drop(columns=[\"label_gdm\"])\n",
    "\n",
    "isolation_instance = IsolationForest(random_state=42)\n",
    "isolation_instance.fit(df_values_cat)\n",
    "df_values_cat[\"is_isolated\"] = isolation_instance.predict(df_values_cat)\n",
    "\n",
    "print(\"\\nIsolation Forest - Todas las variables:\")\n",
    "print(df_values_cat[\"is_isolated\"].value_counts())\n",
    "print(f\"Outliers detectados: {(df_values_cat['is_isolated'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87682102",
   "metadata": {},
   "source": [
    "#### 2.1.5.3 Sistema de Votaci√≥n para Clasificaci√≥n de Outliers\n",
    "\n",
    "Se implementa un sistema de votaci√≥n que combina los 4 m√©todos de detecci√≥n:\n",
    "\n",
    "1. **IQR** (rango intercuart√≠lico)\n",
    "2. **Isolation Forest sobre categ√≥ricas**\n",
    "3. **Isolation Forest sobre continuas**\n",
    "4. **Isolation Forest sobre todas las variables**\n",
    "\n",
    "**Interpretaci√≥n del sistema de votos:**\n",
    "- **0 votos**: Registro normal seg√∫n todos los m√©todos\n",
    "- **1-2 votos**: Posible outlier leve (se conserva)\n",
    "- **3 votos**: Outlier moderado (se elimina)\n",
    "- **4 votos**: Outlier extremo (se elimina)\n",
    "\n",
    "Este enfoque conservador elimina solo casos extremos, preservando la variabilidad biol√≥gica natural del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba58980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columnas de detecci√≥n de outliers al dataframe principal\n",
    "df_data[\"is_outlier_by_IQR\"] = df_outliers[\"outlier_by_IQR\"].values\n",
    "df_data[\"is_outlier_by_IF_all\"] = df_values_cat[\"is_isolated\"].values\n",
    "df_data[\"is_outlier_by_IF_just_values\"] = df_values[\"is_isolated\"].values\n",
    "df_data[\"is_outlier_by_IF_just_cat\"] = data_categorical[\"is_isolated\"].values\n",
    "\n",
    "print(\"Columnas de detecci√≥n agregadas al dataframe principal\")\n",
    "print(f\"Nuevas columnas: {['is_outlier_by_IQR', 'is_outlier_by_IF_all', 'is_outlier_by_IF_just_values', 'is_outlier_by_IF_just_cat']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Verificar integraci√≥n de m√©todos de detecci√≥n en el dataframe principal\n",
    "# Utilidad: Confirmar que todas las columnas de detecci√≥n se agregaron correctamente\n",
    "# y que el dataframe mantiene su integridad estructural\n",
    "print(\"üìã Verificaci√≥n de integraci√≥n de m√©todos de detecci√≥n:\")\n",
    "print(f\"Dimensiones del dataframe: {df_data.shape}\")\n",
    "print(f\"\\nüîç Nuevas columnas agregadas:\")\n",
    "detection_cols = ['is_outlier_by_IQR', 'is_outlier_by_IF_all', 'is_outlier_by_IF_just_values', 'is_outlier_by_IF_just_cat']\n",
    "for col in detection_cols:\n",
    "    if col in df_data.columns:\n",
    "        print(f\"  ‚úì {col}\")\n",
    "print(\"\\nüìä Primeras 5 filas con columnas de detecci√≥n:\")\n",
    "df_data[detection_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizar IQR: convertir conteo a binario (0 = no outlier, 1 = outlier)\n",
    "df_data[\"is_outlier_by_IQR\"] = df_data[\"is_outlier_by_IQR\"].apply(categorize_iqr)\n",
    "\n",
    "print(\"\\nDistribuci√≥n de outliers por IQR (categorizado):\")\n",
    "print(df_data[\"is_outlier_by_IQR\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapear valores de Isolation Forest: 1 (normal) ‚Üí 0, -1 (outlier) ‚Üí 1\n",
    "for column in [\"is_outlier_by_IF_all\", \"is_outlier_by_IF_just_values\", \"is_outlier_by_IF_just_cat\"]:\n",
    "    df_data[column] = df_data[column].replace({1:0, -1:1})\n",
    "\n",
    "print(\"\\nValores de Isolation Forest remapeados:\")\n",
    "print(\"  1 (normal) ‚Üí 0 (no outlier)\")\n",
    "print(\"  -1 (anomal√≠a) ‚Üí 1 (outlier)\")\n",
    "print(\"\\nDistribuci√≥n de outliers por IF (todas las variables):\")\n",
    "print(df_data[\"is_outlier_by_IF_all\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de votaci√≥n: sumar los 4 m√©todos (valores de 0 a 4)\n",
    "df_data[\"vote_outlier\"] = df_data[[\"is_outlier_by_IF_all\", \"is_outlier_by_IF_just_values\", \n",
    "                                     \"is_outlier_by_IF_just_cat\", \"is_outlier_by_IQR\"]].sum(axis=1)\n",
    "\n",
    "print(\"\\nüìä Distribuci√≥n de votos de outliers:\")\n",
    "print(df_data[\"vote_outlier\"].value_counts().sort_index())\n",
    "print(f\"\\nüîç Registros identificados como outliers por los 4 m√©todos: {(df_data['vote_outlier'] == 4).sum()}\")\n",
    "print(f\"‚ö†Ô∏è  Registros identificados como outliers por 3+ m√©todos: {(df_data['vote_outlier'] >= 3).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n detallada: An√°lisis de casos con m√°xima votaci√≥n de outliers\n",
    "# Utilidad: Identificar qu√© caracter√≠sticas tienen los registros m√°s an√≥malos\n",
    "# Estos son candidatos muy fuertes a ser outliers verdaderos que deben eliminarse\n",
    "print(\"üî¨ AN√ÅLISIS DE CASOS EXTREMOS (vote_outlier = 4):\")\n",
    "print(\"=\" * 70)\n",
    "casos_extremos = df_data[df_data[\"vote_outlier\"] == 4]\n",
    "if len(casos_extremos) > 0:\n",
    "    print(f\"Total de casos identificados por los 4 m√©todos: {len(casos_extremos)}\")\n",
    "    print(\"\\nüìä Muestra de registros extremos:\")\n",
    "    # Mostrar algunas variables clave para entender por qu√© son outliers\n",
    "    cols_interes = [\"age_years\", \"bmi_prepreg_kg_m2\", \"fpg_mmol_l\", \"hba1c_percent\", \n",
    "                    \"parity\", \"label_gdm\", \"vote_outlier\"]\n",
    "    print(casos_extremos[cols_interes].head(10))\n",
    "else:\n",
    "    print(\"‚úì No hay registros identificados como outliers por los 4 m√©todos simult√°neamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781730d1",
   "metadata": {},
   "source": [
    "#### 2.1.5.4 Filtrado de Outliers y Creaci√≥n del Dataset Limpio\n",
    "\n",
    "**Criterio de filtrado:** Se eliminan registros identificados como outliers por **3 o m√°s m√©todos** (vote_outlier ‚â• 3).\n",
    "\n",
    "**Justificaci√≥n:** Esta estrategia conservadora elimina solo los casos m√°s extremos, preservando la mayor parte de los datos para an√°lisis posteriores y manteniendo la representatividad de la variabilidad cl√≠nica real.\n",
    "\n",
    "El dataset resultante (`df_filter`) se utilizar√° en todos los an√°lisis subsecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463234d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar outliers: mantener solo registros con vote_outlier < 3\n",
    "df_filter = df_data[df_data[\"vote_outlier\"] < 3].copy()\n",
    "\n",
    "print(f\"‚úÖ Dataset filtrado creado: df_filter\")\n",
    "print(f\"üìä Dimensiones originales: {df_data.shape}\")\n",
    "print(f\"üìä Dimensiones filtradas: {df_filter.shape}\")\n",
    "print(f\"üóëÔ∏è  Registros eliminados: {df_data.shape[0] - df_filter.shape[0]} ({((df_data.shape[0] - df_filter.shape[0]) / df_data.shape[0] * 100):.2f}%)\")\n",
    "print(f\"\\n‚úì Variable cr√≠tica 'df_filter' creada exitosamente para an√°lisis posteriores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b862d",
   "metadata": {},
   "source": [
    "### 2.1.6 Visualizaci√≥n Comparativa por Grupo GDM\n",
    "\n",
    "Se generan visualizaciones exploratorias para todas las variables continuas, comparando las distribuciones entre pacientes con diabetes gestacional (GDM+) y sin ella (GDM-). Se utilizan tres tipos complementarios de gr√°ficos para capturar diferentes aspectos de las distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas con KDE para todas las variables continuas (3x5 subplots)\n",
    "_, axis = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "index = 1\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for column in df_statistical[\"descriptor\"].values:\n",
    "    sns.histplot(\n",
    "        data=df_filter, \n",
    "        x=column, \n",
    "        stat=\"count\",\n",
    "        fill=False, \n",
    "        kde=True, \n",
    "        hue=\"label_gdm\", \n",
    "        ax=axis[i][j])\n",
    "    \n",
    "    axis[i][j].set_xlabel(column, fontsize=8)\n",
    "    axis[i][j].set_ylabel(\"Count\", fontsize=8)\n",
    "    axis[i][j].tick_params(labelsize=7)\n",
    "\n",
    "    if index % 5 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "plt.suptitle(\"Distribuci√≥n de Variables Continuas por Grupo GDM (Histogramas + KDE)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24987d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para todas las variables continuas (3x5 subplots)\n",
    "_, axis = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "index = 1\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for column in df_statistical[\"descriptor\"].values:\n",
    "    sns.boxplot(\n",
    "        data=df_filter, \n",
    "        x=column, \n",
    "        fill=False, \n",
    "        hue=\"label_gdm\", \n",
    "        ax=axis[i][j])\n",
    "    \n",
    "    axis[i][j].set_xlabel(column, fontsize=8)\n",
    "    axis[i][j].tick_params(labelsize=7)\n",
    "\n",
    "    if index % 5 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "plt.suptitle(\"Comparaci√≥n de Distribuciones por Grupo GDM (Boxplots)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e84723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violinplots para todas las variables continuas (3x5 subplots)\n",
    "_, axis = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "index = 1\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for column in df_statistical[\"descriptor\"].values:\n",
    "    sns.violinplot(\n",
    "        data=df_filter, \n",
    "        x=column, \n",
    "        fill=False, \n",
    "        hue=\"label_gdm\", \n",
    "        ax=axis[i][j])\n",
    "    \n",
    "    axis[i][j].set_xlabel(column, fontsize=8)\n",
    "    axis[i][j].tick_params(labelsize=7)\n",
    "\n",
    "    if index % 5 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "plt.suptitle(\"Distribuci√≥n y Densidad por Grupo GDM (Violinplots)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d525017",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Intervalos de Confianza\n",
    "\n",
    "### Introducci√≥n\n",
    "\n",
    "Los intervalos de confianza permiten estimar rangos plausibles para par√°metros poblacionales (media, varianza) a partir de la muestra observada. En el contexto cl√≠nico, estos intervalos proporcionan informaci√≥n sobre la precisi√≥n de nuestras estimaciones y permiten comparar valores observados con rangos de referencia establecidos.\n",
    "\n",
    "### Metodolog√≠a\n",
    "\n",
    "Se calculan intervalos de confianza al 95% para:\n",
    "- **Media (Œº)**: Utilizando la distribuci√≥n t de Student\n",
    "- **Varianza (œÉ¬≤)**: Utilizando la distribuci√≥n chi-cuadrado\n",
    "\n",
    "Se eval√∫a el efecto del tama√±o muestral (n) sobre la amplitud de los intervalos, variando n desde 10 hasta 100 observaciones.\n",
    "\n",
    "### Estado de completitud\n",
    "\n",
    "**üü° Completado al 54% - EN PROGRESO**\n",
    "\n",
    "#### Tareas realizadas:\n",
    "- ‚úÖ Funciones de c√°lculo de IC implementadas en `auxiliar_functions.py`\n",
    "- ‚úÖ IC para media y varianza de variables clave (IMC, FPG, HbA1c)\n",
    "- ‚úÖ Evaluaci√≥n del efecto del tama√±o muestral (n = 10 a 100)\n",
    "\n",
    "#### Tareas pendientes:\n",
    "- ‚è≥ Extender c√°lculo a m√°s variables (HDL, presi√≥n arterial sist√≥lica/diast√≥lica/MAP, triglic√©ridos)\n",
    "- ‚è≥ IC para proporciones en variables categ√≥ricas (fumadoras, antecedentes familiares, PCOS, GDM previa)\n",
    "- ‚è≥ IC para diferencia de medias entre grupos GDM vs No-GDM\n",
    "- ‚è≥ Interpretaci√≥n cl√≠nica comparando con rangos de referencia m√©dicos\n",
    "- ‚è≥ Discusi√≥n sobre precisi√≥n de estimaciones seg√∫n tama√±o muestral\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ff89c",
   "metadata": {},
   "source": [
    "### 2.2.1 C√°lculo de Intervalos de Confianza con Diferentes Tama√±os Muestrales\n",
    "\n",
    "Se eval√∫a c√≥mo var√≠a la amplitud de los intervalos de confianza en funci√≥n del tama√±o de la muestra (n), utilizando muestreo aleatorio repetido para variables cl√≠nicas clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feee6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(10, 100, 10)  # Tama√±os de muestra de 10 a 100\n",
    "print(\"Tama√±os de muestra a evaluar:\")\n",
    "print(n)\n",
    "\n",
    "nro_tamanhos = n.size\n",
    "np.random.seed(42)\n",
    "\n",
    "# Intervalos de confianza\n",
    "for i in range(0, nro_tamanhos):\n",
    "    df_mini = pd.DataFrame()\n",
    "    picked_up_indexs = []\n",
    "    index = None\n",
    "\n",
    "    for j in range(0, int(n[i])):    \n",
    "        while index in picked_up_indexs:\n",
    "            index = np.random.randint(0, df_data.shape[0])\n",
    "            df_mini = pd.concat([df_mini, df_data.iloc[[index]]])\n",
    "        picked_up_indexs.append(index)\n",
    "    \n",
    "    # Intervalos de confianza para variables clave\n",
    "    interesting_descriptors_names = [\"bmi_prepreg_kg_m2\", \"fpg_mmol_l\", \"hba1c_percent\"]\n",
    "\n",
    "    for descriptor_name in interesting_descriptors_names:\n",
    "        descriptor = df_mini[descriptor_name]\n",
    "        descriptor_mean = descriptor.mean()\n",
    "        descriptor_std = descriptor.std()\n",
    "        IC_mean = calculate_ic_mean(descriptor_mean, descriptor_std, int(n[i]))\n",
    "        IC_std = calculate_ic_std(descriptor_std, int(n[i]))\n",
    "        print(f\"Para n={int(n[i])} el intervalo de confianza para la media (Œº) del descriptor '{descriptor_name}' es [{IC_mean[0]:.4f}, {IC_mean[1]:.4f}]\")\n",
    "        print(f\"Para n={int(n[i])} el intervalo de confianza para la varianza (œÉ¬≤) del descriptor '{descriptor_name}' es [{IC_std[0]:.4f}, {IC_std[1]:.4f}]\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c86ff4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Pruebas de Hip√≥tesis\n",
    "\n",
    "### Introducci√≥n\n",
    "\n",
    "Las pruebas de hip√≥tesis permiten evaluar afirmaciones sobre par√°metros poblacionales mediante el an√°lisis de evidencia muestral. En este estudio, se comparan grupos (GDM+ vs GDM-) y se eval√∫an asociaciones entre variables categ√≥ricas y el riesgo de diabetes gestacional.\n",
    "\n",
    "### Metodolog√≠a\n",
    "\n",
    "Para cada comparaci√≥n se sigue el siguiente protocolo:\n",
    "\n",
    "1. **Formulaci√≥n de hip√≥tesis**: Definici√≥n clara de H‚ÇÄ (hip√≥tesis nula) y H‚ÇÅ (hip√≥tesis alternativa)\n",
    "2. **Verificaci√≥n de supuestos**:\n",
    "   - Normalidad por grupo (prueba de Shapiro-Wilk)\n",
    "   - Homogeneidad de varianzas (prueba de Levene)\n",
    "3. **Selecci√≥n de prueba apropiada**:\n",
    "   - **t de Student**: Si se cumplen normalidad y homocedasticidad\n",
    "   - **Welch t-test**: Si se cumple normalidad pero no homocedasticidad\n",
    "   - **Mann-Whitney U**: Si no se cumple normalidad (alternativa no param√©trica)\n",
    "4. **Interpretaci√≥n de resultados**: Decisi√≥n sobre H‚ÇÄ y significancia cl√≠nica\n",
    "\n",
    "### Estado de completitud\n",
    "\n",
    "**üî¥ Completado al 8% - CR√çTICO**\n",
    "\n",
    "#### Tareas realizadas:\n",
    "- ‚úÖ Funci√≥n `compare_two_groups_numeric` implementada (selecci√≥n autom√°tica de test apropiado)\n",
    "- ‚úÖ Comparaci√≥n preliminar de presi√≥n arterial (sist√≥lica, diast√≥lica, MAP) entre grupos GDM\n",
    "\n",
    "#### Tareas pendientes (PRIORITARIAS):\n",
    "- ‚è≥ Formular hip√≥tesis H‚ÇÄ y H‚ÇÅ para todas las comparaciones planificadas\n",
    "- ‚è≥ Comparar variables metab√≥licas clave: IMC, FPG, HbA1c, HOMA-IR, insulina\n",
    "- ‚è≥ Comparar variables lip√≠dicas: triglic√©ridos, HDL\n",
    "- ‚è≥ Comparar edad entre grupos GDM vs No-GDM\n",
    "- ‚è≥ Evaluar diferencias en dieta seg√∫n nivel de actividad f√≠sica (ANOVA/Kruskal-Wallis)\n",
    "- ‚è≥ Pruebas de proporciones (chi-cuadrado o z-test):\n",
    "  - Antecedentes familiares de DM2 vs GDM\n",
    "  - PCOS vs GDM\n",
    "  - Tabaquismo vs GDM\n",
    "  - GDM previa vs recurrencia\n",
    "- ‚è≥ Calcular y reportar tama√±o de efecto:\n",
    "  - d de Cohen para tests param√©tricos\n",
    "  - r de Pearson para Mann-Whitney\n",
    "- ‚è≥ Interpretar todos los resultados en contexto cl√≠nico\n",
    "- ‚è≥ Sintetizar hallazgos en tabla resumen\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a716d3b",
   "metadata": {},
   "source": [
    "### 2.3.1 Comparaci√≥n de Variables Continuas entre Grupos GDM\n",
    "\n",
    "A continuaci√≥n se presenta un ejemplo de comparaci√≥n de presi√≥n arterial entre grupos, utilizando la funci√≥n implementada que verifica supuestos y selecciona autom√°ticamente la prueba estad√≠stica apropiada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_groups_numeric(df, y_col, group_col=\"label_gdm\", alpha=0.05, tail=\"two-sided\"):\n",
    "    \"\"\"\n",
    "    Compara una variable num√©rica (y_col) entre dos grupos binarios (group_col).\n",
    "    Verifica supuestos: normalidad por grupo (Shapiro) y homogeneidad (Levene).\n",
    "    Decide autom√°ticamente entre:\n",
    "      - t de Student cl√°sico (varianzas iguales)\n",
    "      - Welch t-test (varianzas desiguales)\n",
    "      - Mann‚ÄìWhitney U (si falla normalidad)\n",
    "    Retorna un dict con todo lo necesario para el informe.\n",
    "    \"\"\"\n",
    "    d = df[[y_col, group_col]].dropna()\n",
    "    g0 = d[d[group_col] == 0][y_col].astype(float).values\n",
    "    g1 = d[d[group_col] == 1][y_col].astype(float).values\n",
    "\n",
    "    # Hip√≥tesis\n",
    "    H0 = f\"Œº_{y_col}|GDM=0 == Œº_{y_col}|GDM=1\"\n",
    "    H1 = f\"Œº_{y_col}|GDM=0 != Œº_{y_col}|GDM=1\" if tail==\"two-sided\" else f\"Œº diferencias unilaterales ({tail})\"\n",
    "\n",
    "    # Normalidad por grupo (solo si n>=3)\n",
    "    sh0 = stats.shapiro(g0) if len(g0) >= 3 else (np.nan, np.nan)\n",
    "    sh1 = stats.shapiro(g1) if len(g1) >= 3 else (np.nan, np.nan)\n",
    "    normal_ok = (not np.isnan(sh0[1]) and sh0[1] > alpha) and (not np.isnan(sh1[1]) and sh1[1] > alpha)\n",
    "\n",
    "    # Homogeneidad de varianzas (Levene)\n",
    "    lev = stats.levene(g0, g1, center='median')\n",
    "    equal_var = lev.pvalue > alpha\n",
    "\n",
    "    # Elecci√≥n de prueba\n",
    "    if normal_ok:\n",
    "        res = stats.ttest_ind(g0, g1, equal_var=equal_var, alternative=\"two-sided\")\n",
    "        test_name = \"t-test (Welch)\" if not equal_var else \"t-test (varianzas iguales)\"\n",
    "        stat, p = res.statistic, res.pvalue\n",
    "    else:\n",
    "        res = stats.mannwhitneyu(g0, g1, alternative=\"two-sided\")\n",
    "        test_name = \"Mann‚ÄìWhitney U\"\n",
    "        stat, p = res.statistic, res.pvalue\n",
    "\n",
    "    decision = \"Rechazo H0\" if p < alpha else \"No rechazo H0\"\n",
    "\n",
    "    return {\n",
    "        \"variable\": y_col,\n",
    "        \"n_gdm0\": len(g0), \"mean_gdm0\": np.mean(g0), \"sd_gdm0\": np.std(g0, ddof=1),\n",
    "        \"n_gdm1\": len(g1), \"mean_gdm1\": np.mean(g1), \"sd_gdm1\": np.std(g1, ddof=1),\n",
    "        \"shapiro_g0_p\": (np.nan if np.isnan(sh0[1]) else sh0[1]),\n",
    "        \"shapiro_g1_p\": (np.nan if np.isnan(sh1[1]) else sh1[1]),\n",
    "        \"levene_p\": lev.pvalue,\n",
    "        \"test\": test_name, \"stat\": stat, \"p_value\": p,\n",
    "        \"alpha\": alpha, \"decision\": decision,\n",
    "        \"H0\": H0, \"H1\": H1\n",
    "    }\n",
    "\n",
    "# Ejemplo: Comparaci√≥n de presi√≥n arterial\n",
    "print(\"Comparaci√≥n de presi√≥n arterial entre grupos GDM vs No-GDM:\")\n",
    "print(\"=\" * 70)\n",
    "for col in [\"systolic_bp_mmHg\", \"diastolic_bp_mmHg\", \"map_mmHg\"]:\n",
    "    out = compare_two_groups_numeric(df_data, y_col=col, group_col=\"label_gdm\", alpha=0.05)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87efb4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Evaluaci√≥n de Normalidad\n",
    "\n",
    "### Introducci√≥n\n",
    "\n",
    "La evaluaci√≥n de la normalidad de las distribuciones es un paso crucial en el an√°lisis estad√≠stico, ya que determina la validez de pruebas param√©tricas (t-test, ANOVA) y justifica el uso de alternativas no param√©tricas cuando los supuestos no se cumplen.\n",
    "\n",
    "### Metodolog√≠a\n",
    "\n",
    "Se aplican dos pruebas complementarias de normalidad:\n",
    "\n",
    "1. **Shapiro-Wilk (SW)**: Prueba de m√°xima potencia para detectar desviaciones de la normalidad en muestras peque√±as y medianas (recomendada como prueba principal)\n",
    "2. **Kolmogorov-Smirnov con correcci√≥n de Lilliefors (KS)**: Compara la distribuci√≥n emp√≠rica con la normal te√≥rica\n",
    "\n",
    "**Criterio de decisi√≥n:** Œ± = 0.05\n",
    "- **p ‚â• 0.05**: No se rechaza H‚ÇÄ (distribuci√≥n compatible con normalidad)\n",
    "- **p < 0.05**: Se rechaza H‚ÇÄ (distribuci√≥n no normal)\n",
    "\n",
    "**Interpretaci√≥n:** Se priorizan los resultados de Shapiro-Wilk por su mayor sensibilidad. La concordancia entre ambas pruebas refuerza las conclusiones.\n",
    "\n",
    "### Estado de completitud\n",
    "\n",
    "**üü¢ Completado al 85% - CASI COMPLETO**\n",
    "\n",
    "#### Tareas realizadas:\n",
    "- ‚úÖ Prueba de Shapiro-Wilk para todas las variables continuas\n",
    "- ‚úÖ Prueba de Kolmogorov-Smirnov (Lilliefors) para todas las variables continuas\n",
    "- ‚úÖ Resumen tabular de resultados con decisi√≥n (Normal / No normal)\n",
    "- ‚úÖ Comparaci√≥n sistem√°tica entre ambos tests\n",
    "\n",
    "#### Tareas pendientes:\n",
    "- ‚è≥ Generar QQ-plots (gr√°ficos cuantil-cuantil) para cada variable continua\n",
    "- ‚è≥ Crear histogramas con curva normal te√≥rica superpuesta\n",
    "- ‚è≥ Probar transformaciones en variables asim√©tricas:\n",
    "  - Transformaci√≥n logar√≠tmica (log)\n",
    "  - Transformaci√≥n Box-Cox\n",
    "  - Transformaci√≥n ra√≠z cuadrada\n",
    "- ‚è≥ Re-evaluar normalidad post-transformaci√≥n\n",
    "- ‚è≥ Sintetizar implicancias para elecci√≥n de pruebas estad√≠sticas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c471b0",
   "metadata": {},
   "source": [
    "### 2.4.1 Aplicaci√≥n de Pruebas de Normalidad\n",
    "\n",
    "Se eval√∫a la normalidad de todas las variables continuas mediante Shapiro-Wilk y Kolmogorov-Smirnov, comparando los resultados de ambas pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables = [\n",
    "    \"age_years\", \"bmi_prepreg_kg_m2\", \"systolic_bp_mmHg\", \"diastolic_bp_mmHg\", \n",
    "    \"map_mmHg\", \"gestational_weeks\", \"fpg_mmol_l\", \"hba1c_percent\", \n",
    "    \"insulin_uIU_ml\", \"homa_ir\", \"triglycerides_mmol_l\", \"hdl_mmol_l\", \n",
    "    \"physical_activity_level\", \"diet_score_0_100\"\n",
    "]\n",
    "\n",
    "# Inicializar estructuras\n",
    "clean_data_descriptors = []\n",
    "n_val = []\n",
    "n_invalid = []\n",
    "\n",
    "# Limpiar NaN por variable\n",
    "for var in continuous_variables:\n",
    "    valid_data = df_data[var].dropna()\n",
    "    n_validos = valid_data.size\n",
    "    n_faltantes = df_data[var].isna().sum()\n",
    "\n",
    "    clean_data_descriptors.append(valid_data)\n",
    "    n_val.append(n_validos)\n",
    "    n_invalid.append(n_faltantes)\n",
    "\n",
    "# Prueba de normalidad\n",
    "normality_results = []\n",
    "alpha = 0.05\n",
    "\n",
    "# Evaluar cada variable\n",
    "for idx, var in enumerate(continuous_variables):\n",
    "    x = clean_data_descriptors[idx]\n",
    "\n",
    "    # Shapiro‚ÄìWilk\n",
    "    W, p_sw = stats.shapiro(x)\n",
    "    \n",
    "    # KS-Lilliefors (usando par√°metros estimados)\n",
    "    mu, sigma = x.mean(), x.std(ddof=1)\n",
    "    D, p_ks = stats.kstest(x, 'norm', args=(mu, sigma))\n",
    "    \n",
    "    # Decisi√≥n\n",
    "    decision_sw = \"Normal\" if p_sw >= alpha else \"No normal\"\n",
    "    decision_ks = \"Normal\" if p_ks >= alpha else \"No normal\"\n",
    "    \n",
    "    # Guardar resultado\n",
    "    normality_results.append({\n",
    "        \"Variable\": var,\n",
    "        \"n\": len(x),\n",
    "        \"SW_W\": W,\n",
    "        \"SW_p\": p_sw,\n",
    "        \"SW_decisi√≥n\": decision_sw,\n",
    "        \"KS_D\": D,\n",
    "        \"KS_p\": p_ks,\n",
    "        \"KS_decisi√≥n\": decision_ks\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Resultados de pruebas de normalidad:\")\n",
    "print(\"=\" * 100)\n",
    "for result in normality_results:\n",
    "    print(f\"\\n{result['Variable']}:\")\n",
    "    print(f\"  n={result['n']}\")\n",
    "    print(f\"  Shapiro-Wilk: W={result['SW_W']:.4f}, p={result['SW_p']:.4f} ‚Üí {result['SW_decisi√≥n']}\")\n",
    "    print(f\"  KS-Lilliefors: D={result['KS_D']:.4f}, p={result['KS_p']:.4f} ‚Üí {result['KS_decisi√≥n']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16a148",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 An√°lisis Bivariado\n",
    "\n",
    "### Introducci√≥n\n",
    "\n",
    "El an√°lisis bivariado examina las relaciones entre pares de variables, permitiendo identificar asociaciones, patrones de correlaci√≥n y diferencias entre grupos. Este an√°lisis es fundamental para comprender la estructura de dependencias en los datos y generar hip√≥tesis sobre posibles relaciones causales.\n",
    "\n",
    "### Metodolog√≠a\n",
    "\n",
    "Se implementan las siguientes t√©cnicas:\n",
    "\n",
    "1. **Matrices de correlaci√≥n**:\n",
    "   - **Pearson**: Mide asociaci√≥n lineal entre variables continuas\n",
    "   - **Spearman**: Mide asociaci√≥n monot√≥nica (m√°s robusta a outliers)\n",
    "2. **An√°lisis estratificado por grupo GDM**:\n",
    "   - Correlaciones separadas para GDM+ y GDM-\n",
    "   - Matriz de diferencias entre grupos\n",
    "3. **Visualizaciones**:\n",
    "   - Heatmaps de correlaci√≥n con anotaciones num√©ricas\n",
    "   - Pairplot comprehensivo con separaci√≥n por grupo GDM\n",
    "\n",
    "**Preparaci√≥n de datos:** Se eliminan variables categ√≥ricas y columnas de detecci√≥n de outliers, conservando solo variables continuas m√°s la etiqueta GDM.\n",
    "\n",
    "### Estado de completitud\n",
    "\n",
    "**‚úÖ Completado al 100%**\n",
    "\n",
    "#### Tareas realizadas:\n",
    "- ‚úÖ Preparaci√≥n del dataset limpio (`df_filter_clean`)\n",
    "- ‚úÖ Matriz de correlaci√≥n de Pearson (todas las variables continuas)\n",
    "- ‚úÖ Matriz de correlaci√≥n de Spearman (todas las variables continuas)\n",
    "- ‚úÖ Heatmap de correlaci√≥n Pearson con identificaci√≥n autom√°tica de correlaciones fuertes (|r| > 0.7)\n",
    "- ‚úÖ Correlaciones separadas por grupo (GDM+ vs GDM-)\n",
    "- ‚úÖ Heatmaps individuales por grupo con escalas de color diferenciadas\n",
    "- ‚úÖ Heatmap de diferencias entre grupos (GDM- - GDM+)\n",
    "- ‚úÖ Pairplot completo con visualizaci√≥n por grupo GDM\n",
    "- ‚úÖ Identificaci√≥n y reporte de mayores diferencias en correlaci√≥n entre grupos\n",
    "\n",
    "#### Tareas opcionales pendientes:\n",
    "- ‚è≥ Scatterplots con l√≠neas de regresi√≥n para pares clave (FPG vs HbA1c, Insulina vs HOMA-IR)\n",
    "- ‚è≥ Incluir ecuaci√≥n de regresi√≥n y R¬≤ en gr√°ficos\n",
    "- ‚è≥ Interpretaci√≥n cl√≠nica detallada de todas las asociaciones encontradas\n",
    "- ‚è≥ Relacionar hallazgos con literatura cient√≠fica sobre fisiopatolog√≠a de GDM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bf1b7",
   "metadata": {},
   "source": [
    "### 2.5.1 Preparaci√≥n de Datos y Matrices de Correlaci√≥n\n",
    "\n",
    "Se prepara el dataset eliminando variables no continuas y se calculan las matrices de correlaci√≥n de Pearson y Spearman para identificar asociaciones entre variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Recordatorio de variables categ√≥ricas a excluir del an√°lisis\n",
    "# Utilidad: Clarificar qu√© variables no deben incluirse en correlaciones\n",
    "# Las correlaciones de Pearson/Spearman son para variables continuas\n",
    "print(\"üìù Recordatorio - Variables categ√≥ricas/binarias (excluidas de correlaciones):\")\n",
    "print(columns_to_ignore)\n",
    "print(f\"\\nEstas {len(columns_to_ignore)} variables ser√°n eliminadas junto con las de detecci√≥n de outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n: Verificar estructura del dataset filtrado antes del an√°lisis bivariado\n",
    "# Utilidad: Confirmar qu√© columnas est√°n disponibles y cu√°les deben eliminarse\n",
    "# para el an√°lisis de correlaciones (solo variables continuas)\n",
    "print(\"üîç INSPECCI√ìN PRE-AN√ÅLISIS BIVARIADO:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Dimensiones de df_filter: {df_filter.shape}\")\n",
    "print(f\"\\nüìã Columnas actuales en df_filter:\")\n",
    "print(df_filter.columns.tolist())\n",
    "print(f\"\\nüìä Total de columnas: {len(df_filter.columns)}\")\n",
    "print(f\"   - Variables originales: {len([c for c in df_filter.columns if not c.startswith('is_outlier') and c != 'vote_outlier'])}\")\n",
    "print(f\"   - Columnas de detecci√≥n de outliers: {len([c for c in df_filter.columns if c.startswith('is_outlier') or c == 'vote_outlier'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para an√°lisis bivariado: eliminar columnas de detecci√≥n de outliers\n",
    "df_filter_clean = df_filter.drop(columns=['is_outlier_by_IQR', 'is_outlier_by_IF_all', \n",
    "                                           'is_outlier_by_IF_just_values', 'is_outlier_by_IF_just_cat', \n",
    "                                           'vote_outlier', 'parity', 'family_history_t2d', 'previous_gdm',\n",
    "                                           'pcos', 'smoking_first_trimester', 'physical_activity_level'])\n",
    "\n",
    "print(\"‚úÖ Dataset limpio para an√°lisis bivariado creado\")\n",
    "print(f\"üìä Variables para correlaci√≥n: {df_filter_clean.shape[1] - 1} (excluyendo label_gdm)\")\n",
    "print(f\"Variables: {list(df_filter_clean.drop(columns=['label_gdm']).columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular correlaci√≥n de Pearson y Spearman\n",
    "df_corr_pearson = df_filter_clean.drop(columns=[\"label_gdm\"]).corr(method=\"pearson\")\n",
    "df_corr_spearman = df_filter_clean.drop(columns=[\"label_gdm\"]).corr(method=\"spearman\")\n",
    "\n",
    "print(\"‚úÖ Correlaciones calculadas:\")\n",
    "print(\"  - Pearson (lineal)\")\n",
    "print(\"  - Spearman (monot√≥nica)\")\n",
    "\n",
    "# Visualizar heatmap de Pearson\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(data=df_corr_pearson, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar_kws={'label': 'Correlaci√≥n de Pearson'})\n",
    "plt.title(\"Matriz de Correlaci√≥n de Pearson - Variables Continuas\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Correlaciones fuertes encontradas (|r| > 0.7):\")\n",
    "print(\"=\" * 50)\n",
    "# Identificar correlaciones fuertes\n",
    "strong_corr_found = False\n",
    "for i in range(len(df_corr_pearson.columns)):\n",
    "    for j in range(i+1, len(df_corr_pearson.columns)):\n",
    "        corr_value = df_corr_pearson.iloc[i, j]\n",
    "        if abs(corr_value) > 0.7:\n",
    "            print(f\"{df_corr_pearson.columns[i]} vs {df_corr_pearson.columns[j]}: r = {corr_value:.3f}\")\n",
    "            strong_corr_found = True\n",
    "\n",
    "if not strong_corr_found:\n",
    "    print(\"No se encontraron correlaciones > 0.7 (esperado en datos sint√©ticos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802da4ac",
   "metadata": {},
   "source": [
    "### 2.5.2 An√°lisis de Correlaciones por Grupo GDM\n",
    "\n",
    "Se calculan matrices de correlaci√≥n separadas para pacientes con y sin GDM, permitiendo identificar si las relaciones entre variables difieren seg√∫n el estado de diabetes gestacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ae927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlaciones separadas por grupo\n",
    "df_corr_pearson_pos = df_filter_clean[df_filter_clean[\"label_gdm\"] == 1].drop(columns=[\"label_gdm\"]).corr(method=\"pearson\")\n",
    "df_corr_pearson_neg = df_filter_clean[df_filter_clean[\"label_gdm\"] == 0].drop(columns=[\"label_gdm\"]).corr(method=\"pearson\")\n",
    "\n",
    "print(f\"‚úÖ Correlaciones por grupo calculadas:\")\n",
    "print(f\"  - GDM+ (positivo): {(df_filter_clean['label_gdm'] == 1).sum()} pacientes\")\n",
    "print(f\"  - GDM- (negativo): {(df_filter_clean['label_gdm'] == 0).sum()} pacientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap para grupo GDM+ (positivo)\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(data=df_corr_pearson_pos, annot=True, fmt=\".2f\", cmap=\"Reds\", \n",
    "            cbar_kws={'label': 'Correlaci√≥n de Pearson'})\n",
    "plt.title(\"Correlaci√≥n de Pearson - Pacientes con GDM (Positivo)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d756bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap para grupo GDM- (negativo)\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(data=df_corr_pearson_neg, annot=True, fmt=\".2f\", cmap=\"Greens\", \n",
    "            cbar_kws={'label': 'Correlaci√≥n de Pearson'})\n",
    "plt.title(\"Correlaci√≥n de Pearson - Pacientes sin GDM (Negativo)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de diferencias entre grupos (GDM- menos GDM+)\n",
    "plt.figure(figsize=(14, 12))\n",
    "df_corr_diff = df_corr_pearson_neg - df_corr_pearson_pos\n",
    "sns.heatmap(data=df_corr_diff, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0,\n",
    "            cbar_kws={'label': 'Diferencia de Correlaci√≥n (GDM- - GDM+)'})\n",
    "plt.title(\"Diferencias en Correlaci√≥n entre Grupos (GDM- - GDM+)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Mayores diferencias en correlaci√≥n entre grupos:\")\n",
    "print(\"=\" * 70)\n",
    "# Encontrar las mayores diferencias\n",
    "diff_values = []\n",
    "for i in range(len(df_corr_diff.columns)):\n",
    "    for j in range(i+1, len(df_corr_diff.columns)):\n",
    "        diff = df_corr_diff.iloc[i, j]\n",
    "        if abs(diff) > 0.2:  # Diferencias mayores a 0.2\n",
    "            diff_values.append((df_corr_diff.columns[i], df_corr_diff.columns[j], diff))\n",
    "\n",
    "if diff_values:\n",
    "    for var1, var2, diff in sorted(diff_values, key=lambda x: abs(x[2]), reverse=True)[:5]:\n",
    "        print(f\"{var1} vs {var2}: Œîr = {diff:.3f}\")\n",
    "else:\n",
    "    print(\"No se encontraron diferencias sustanciales (> 0.2) entre grupos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650f5ad",
   "metadata": {},
   "source": [
    "### 2.5.3 Visualizaci√≥n Comprehensiva: Pairplot\n",
    "\n",
    "Se genera un pairplot que muestra todas las relaciones bivariadas entre variables continuas, con separaci√≥n visual por grupo GDM. Esta visualizaci√≥n permite identificar patrones, agrupamientos y diferencias entre grupos de forma simult√°nea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot completo con separaci√≥n por grupo GDM\n",
    "print(\"‚è≥ Generando pairplot (puede tardar unos segundos)...\")\n",
    "pairplot_fig = sns.pairplot(data=df_filter_clean, hue=\"label_gdm\", \n",
    "                             diag_kind=\"kde\", plot_kws={'alpha': 0.6},\n",
    "                             palette={0: \"green\", 1: \"red\"})\n",
    "pairplot_fig.fig.suptitle(\"Relaciones Bivariadas - Todas las Variables por Grupo GDM\", \n",
    "                          y=1.01, fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚úÖ Pairplot generado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a04ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n final: Verificaci√≥n del dataset limpio usado en an√°lisis bivariado\n",
    "# Utilidad: Confirmar que df_filter_clean contiene solo variables continuas + label_gdm\n",
    "# y que no hay valores faltantes que puedan afectar las correlaciones\n",
    "print(\"‚úÖ VERIFICACI√ìN FINAL DEL DATASET PARA AN√ÅLISIS BIVARIADO:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä Dimensiones de df_filter_clean: {df_filter_clean.shape}\")\n",
    "print(f\"   Registros: {df_filter_clean.shape[0]} (despu√©s de filtrar outliers)\")\n",
    "print(f\"   Variables: {df_filter_clean.shape[1]} (solo continuas + label_gdm)\")\n",
    "print(f\"\\nüìã Variables incluidas:\")\n",
    "print(df_filter_clean.columns.tolist())\n",
    "print(f\"\\nüîç Valores faltantes por variable:\")\n",
    "missing = df_filter_clean.isna().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"   ‚úì No hay valores faltantes en el dataset limpio\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "print(f\"\\n‚úì Dataset listo para an√°lisis de correlaciones y visualizaciones bivariadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce017ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.6 Interpretaci√≥n Cl√≠nica y Conclusiones\n",
    "\n",
    "### Introducci√≥n\n",
    "\n",
    "Esta secci√≥n sintetiza los hallazgos del an√°lisis exploratorio y proporciona una interpretaci√≥n de los resultados en el contexto cl√≠nico de la diabetes gestacional, discutiendo implicancias, limitaciones y recomendaciones para an√°lisis futuros.\n",
    "\n",
    "### Estado de completitud\n",
    "\n",
    "**üî¥ Completado al 0% - CR√çTICO - SECCI√ìN PRIORITARIA**\n",
    "\n",
    "Esta secci√≥n requiere desarrollo urgente para completar el informe. A continuaci√≥n se presenta la estructura sugerida basada en los hallazgos obtenidos.\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura de contenido pendiente\n",
    "\n",
    "#### 2.6.1 S√≠ntesis de Hallazgos Principales\n",
    "\n",
    "**Tareas pendientes:**\n",
    "- ‚è≥ Resumir variables con distribuci√≥n no normal y consecuencias para an√°lisis estad√≠stico\n",
    "- ‚è≥ Listar diferencias significativas encontradas entre grupos GDM+ vs GDM-\n",
    "- ‚è≥ Destacar direcci√≥n de las diferencias (qu√© grupo presenta valores m√°s elevados/reducidos)\n",
    "- ‚è≥ Enumerar correlaciones cl√≠nicamente relevantes y su magnitud\n",
    "- ‚è≥ Reportar resultados de intervalos de confianza para variables clave\n",
    "- ‚è≥ Sintetizar resultados de pruebas de hip√≥tesis realizadas\n",
    "\n",
    "#### 2.6.2 Interpretaci√≥n Cl√≠nica de Resultados\n",
    "\n",
    "**Tareas pendientes:**\n",
    "- ‚è≥ Interpretar diferencias entre GDM+ y GDM- en contexto fisiopatol√≥gico\n",
    "- ‚è≥ Discutir relevancia cl√≠nica de correlaciones encontradas\n",
    "- ‚è≥ Comparar valores observados con rangos de referencia cl√≠nicos est√°ndar\n",
    "- ‚è≥ Identificar posibles marcadores tempranos de riesgo de GDM\n",
    "- ‚è≥ Comentar sobre variables con mayor poder discriminante entre grupos\n",
    "- ‚è≥ Discutir relaciones causales plausibles vs correlaciones espurias\n",
    "\n",
    "#### 2.6.3 An√°lisis de Datos Faltantes y su Impacto\n",
    "\n",
    "**Tareas pendientes:**\n",
    "- ‚è≥ Caracterizar patrones de datos faltantes (MCAR vs MAR)\n",
    "- ‚è≥ Evaluar impacto potencial en estimaciones y conclusiones\n",
    "- ‚è≥ Discutir posibles sesgos introducidos por datos ausentes\n",
    "- ‚è≥ Justificar estrategia de manejo (exclusi√≥n por lista vs imputaci√≥n)\n",
    "\n",
    "#### 2.6.4 Limitaciones del Estudio\n",
    "\n",
    "**Tareas pendientes:**\n",
    "- ‚è≥ Discutir naturaleza sint√©tica del dataset y representatividad\n",
    "- ‚è≥ Identificar variables confusoras no controladas\n",
    "- ‚è≥ Comentar sobre posibles sesgos de selecci√≥n\n",
    "- ‚è≥ Mencionar limitaciones del dise√±o transversal (vs longitudinal)\n",
    "- ‚è≥ Discutir desbalance de clases y su impacto en an√°lisis\n",
    "- ‚è≥ Reconocer limitaciones de an√°lisis univariado y bivariado (vs multivariado)\n",
    "\n",
    "#### 2.6.5 Recomendaciones y Pr√≥ximos Pasos\n",
    "\n",
    "**Tareas pendientes:**\n",
    "- ‚è≥ Proponer an√°lisis multivariado (regresi√≥n log√≠stica para GDM)\n",
    "- ‚è≥ Sugerir construcci√≥n de modelo predictivo con validaci√≥n cruzada\n",
    "- ‚è≥ Recomendar an√°lisis de curvas ROC y selecci√≥n de umbrales √≥ptimos\n",
    "- ‚è≥ Proponer estudios longitudinales de seguimiento\n",
    "- ‚è≥ Sugerir validaci√≥n externa en cohortes reales\n",
    "- ‚è≥ Recomendar investigaci√≥n de mecanismos causales subyacentes\n",
    "- ‚è≥ Proponer estrategias de intervenci√≥n temprana basadas en hallazgos\n",
    "\n",
    "---\n",
    "\n",
    "**Nota del equipo:** Esta secci√≥n debe completarse con urgencia antes de la entrega final. Se requiere s√≠ntesis cr√≠tica de todos los an√°lisis realizados y discusi√≥n sustantiva de implicancias cl√≠nicas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfa837",
   "metadata": {},
   "source": [
    "# 3. Entregables y Documentaci√≥n del Proyecto\n",
    "\n",
    "## 3.1 Estructura de Archivos\n",
    "\n",
    "Este trabajo pr√°ctico debe ser entregado como un archivo comprimido (`.tar.gz` o `.zip`) que incluye los siguientes componentes:\n",
    "\n",
    "### Archivos principales del an√°lisis\n",
    "\n",
    "#### 1. **`Entregable.ipynb`** *(este documento)*\n",
    "- Notebook principal con todo el an√°lisis organizado por secciones\n",
    "- Incluye c√≥digo ejecutable, visualizaciones, resultados e interpretaciones\n",
    "- Estructura modular siguiendo la gu√≠a pr√°ctica del profesor\n",
    "- Indicadores de progreso y completitud por secci√≥n\n",
    "- Formato de informe acad√©mico con metodolog√≠a y resultados\n",
    "\n",
    "#### 2. **`gdm_first_trimester_ml_dataset.csv`**\n",
    "- Dataset original con datos cl√≠nicos sint√©ticos\n",
    "- N ‚âà 1500 registros de pacientes embarazadas\n",
    "- 25 variables: demogr√°ficas, antropom√©tricas, hemodin√°micas, metab√≥licas, obst√©tricas y de estilo de vida\n",
    "- Contiene valores faltantes (MCAR y MAR) y outliers simulados\n",
    "\n",
    "#### 3. **`gdm_first_trimester_ml_dataset_metadata.json`**\n",
    "- Archivo de metadatos con descripci√≥n detallada del dataset\n",
    "- Especificaci√≥n de tipos de datos por variable\n",
    "- Informaci√≥n sobre rangos esperados, unidades de medida\n",
    "- Documentaci√≥n de patrones de valores faltantes\n",
    "\n",
    "#### 4. **`auxiliar_functions.py`**\n",
    "- M√≥dulo Python con funciones auxiliares implementadas\n",
    "- Funciones incluidas:\n",
    "  - `calculate_ic_mean()`: Intervalo de confianza para la media\n",
    "  - `calculate_ic_std()`: Intervalo de confianza para la desviaci√≥n est√°ndar\n",
    "  - `get_range_outlier()`: C√°lculo de umbrales IQR para outliers\n",
    "  - `check_is_outlier()`: Verificaci√≥n de outlier por IQR\n",
    "  - `categorize_iqr()`: Categorizaci√≥n binaria de outliers\n",
    "  - `generate_df_counts()`: Generaci√≥n de res√∫menes de conteos\n",
    "- Documentaci√≥n interna con docstrings\n",
    "\n",
    "### Archivos de documentaci√≥n y planificaci√≥n\n",
    "\n",
    "#### 5. **`INSTRUCCIONES.md`**\n",
    "- Gu√≠a pr√°ctica original proporcionada por el profesor\n",
    "- Descripci√≥n detallada de actividades a desarrollar\n",
    "- Especificaci√≥n de entregables y criterios de evaluaci√≥n\n",
    "- Plazos y formato de entrega\n",
    "\n",
    "#### 6. **`TASKS.md`** / **`TASK2.md`**\n",
    "- Archivos de gesti√≥n de tareas del equipo\n",
    "- `TASKS.md`: Lista priorizada de tareas pendientes\n",
    "- `TASK2.md`: Organizaci√≥n de tareas por secci√≥n del an√°lisis\n",
    "- Incluyen estimaciones de tiempo y estado de completitud\n",
    "\n",
    "#### 7. **`README.md`** (en carpeta `__pycache__/`)\n",
    "- Evaluaci√≥n detallada del estado de progreso del proyecto\n",
    "- Retroalimentaci√≥n por secci√≥n con porcentajes de avance\n",
    "- Identificaci√≥n de √°reas cr√≠ticas que requieren atenci√≥n\n",
    "\n",
    "#### 8. **`COMPARACION_MIGRACION.md`**\n",
    "- Documentaci√≥n de verificaci√≥n de migraci√≥n desde prototipo\n",
    "- An√°lisis exhaustivo de completitud del c√≥digo\n",
    "- Confirmaci√≥n de integridad del an√°lisis implementado\n",
    "\n",
    "### Archivos de control de versiones y configuraci√≥n\n",
    "\n",
    "#### 9. **`.gitignore`**\n",
    "- Configuraci√≥n de archivos excluidos del control de versiones\n",
    "- Incluye: `__pycache__/`, `*.pyc`, entornos virtuales, archivos temporales\n",
    "\n",
    "### Archivos de desarrollo (prototipos)\n",
    "\n",
    "#### 10. **`1_check_data.ipynb`**\n",
    "- Prototipo inicial del an√°lisis exploratorio\n",
    "- Desarrollo iterativo del c√≥digo posteriormente migrado a `Entregable.ipynb`\n",
    "- Contiene todas las funcionalidades implementadas y validadas\n",
    "\n",
    "#### 11. **`check_data.ipynb`**\n",
    "- Versi√≥n preliminar del prototipo (obsoleta)\n",
    "- Conservada como referencia hist√≥rica del desarrollo\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 Herramientas y Tecnolog√≠as Utilizadas\n",
    "\n",
    "### Entorno de desarrollo\n",
    "\n",
    "- **Python 3.8+**: Lenguaje de programaci√≥n principal\n",
    "- **Jupyter Notebook / JupyterLab**: Entorno de desarrollo interactivo\n",
    "- **Git**: Sistema de control de versiones\n",
    "- **Visual Studio Code**: Editor de c√≥digo con extensiones para notebooks\n",
    "\n",
    "### Librer√≠as principales\n",
    "\n",
    "#### Manipulaci√≥n y an√°lisis de datos\n",
    "- **pandas (‚â•1.3.0)**: Manipulaci√≥n de estructuras de datos tabulares\n",
    "- **numpy (‚â•1.21.0)**: Operaciones num√©ricas y √°lgebra lineal\n",
    "\n",
    "#### Visualizaci√≥n\n",
    "- **matplotlib (‚â•3.4.0)**: Biblioteca base para gr√°ficos\n",
    "- **seaborn (‚â•0.11.0)**: Visualizaci√≥n estad√≠stica avanzada con est√©tica mejorada\n",
    "\n",
    "#### An√°lisis estad√≠stico\n",
    "- **scipy.stats**: Suite completa de pruebas estad√≠sticas\n",
    "  - Pruebas de normalidad: `shapiro`, `kstest`\n",
    "  - Pruebas de comparaci√≥n: `ttest_ind`, `mannwhitneyu`\n",
    "  - Prueba de homogeneidad: `levene`\n",
    "  - Distribuciones de probabilidad\n",
    "\n",
    "#### Aprendizaje autom√°tico\n",
    "- **scikit-learn (‚â•0.24.0)**:\n",
    "  - `IsolationForest`: Detecci√≥n de anomal√≠as no supervisada\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 Requisitos e Instrucciones de Ejecuci√≥n\n",
    "\n",
    "### Requisitos previos\n",
    "\n",
    "1. **Python 3.8 o superior** instalado en el sistema\n",
    "2. **Jupyter Notebook o JupyterLab** instalado\n",
    "\n",
    "### Instalaci√≥n de dependencias\n",
    "\n",
    "Ejecutar en terminal (PowerShell o Bash):\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn scipy scikit-learn jupyter\n",
    "```\n",
    "\n",
    "**Alternativa:** Usar entorno virtual (recomendado):\n",
    "\n",
    "```bash\n",
    "# Crear entorno virtual\n",
    "python -m venv venv\n",
    "\n",
    "# Activar entorno virtual\n",
    "# En Windows PowerShell:\n",
    ".\\venv\\Scripts\\Activate.ps1\n",
    "# En Linux/Mac:\n",
    "source venv/bin/activate\n",
    "\n",
    "# Instalar dependencias\n",
    "pip install pandas numpy matplotlib seaborn scipy scikit-learn jupyter\n",
    "```\n",
    "\n",
    "### Ejecuci√≥n del notebook\n",
    "\n",
    "1. **Ubicar archivos**: Asegurar que los siguientes archivos est√©n en el mismo directorio:\n",
    "   - `Entregable.ipynb`\n",
    "   - `gdm_first_trimester_ml_dataset.csv`\n",
    "   - `auxiliar_functions.py`\n",
    "\n",
    "2. **Iniciar Jupyter**:\n",
    "   ```bash\n",
    "   jupyter notebook\n",
    "   ```\n",
    "   O:\n",
    "   ```bash\n",
    "   jupyter lab\n",
    "   ```\n",
    "\n",
    "3. **Abrir notebook**: En el navegador, seleccionar `Entregable.ipynb`\n",
    "\n",
    "4. **Ejecutar celdas**: \n",
    "   - **Opci√≥n A (recomendada)**: *Cell ‚Üí Run All* (ejecutar todo secuencialmente)\n",
    "   - **Opci√≥n B**: Ejecutar celdas individualmente con *Shift + Enter*\n",
    "\n",
    "### Notas importantes sobre ejecuci√≥n\n",
    "\n",
    "‚ö†Ô∏è **Advertencias:**\n",
    "- Algunas celdas en secciones incompletas (marcadas con üî¥) pueden no ejecutarse correctamente si dependen de celdas pendientes\n",
    "- El dataset limpio `df_filter` se genera en la secci√≥n 2.1 y es **requisito para secciones posteriores**\n",
    "- El dataset `df_filter_clean` se crea en la secci√≥n 2.5 para an√°lisis bivariado\n",
    "- Las visualizaciones pueden tardar varios segundos en generarse (especialmente el pairplot)\n",
    "- Los resultados de normalidad (secci√≥n 2.4) deben usarse para justificar la selecci√≥n de tests en la secci√≥n 2.3\n",
    "\n",
    "‚úÖ **Recomendaciones:**\n",
    "- Ejecutar el notebook completo al menos una vez antes de realizar modificaciones\n",
    "- Verificar que no hay errores en la consola de Jupyter\n",
    "- Revisar la salida de cada celda para confirmar resultados esperados\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4 Herramientas de Inteligencia Artificial Utilizadas\n",
    "\n",
    "**[COMPLETAR POR EL EQUIPO ANTES DE LA ENTREGA]**\n",
    "\n",
    "*Indicar aqu√≠ si se utiliz√≥ alguna herramienta de IA (ChatGPT, GitHub Copilot, etc.) y para qu√© tareas espec√≠ficas.*\n",
    "\n",
    "**Ejemplo de formato:**\n",
    "\n",
    "> **GitHub Copilot:**\n",
    "> - Generaci√≥n de c√≥digo auxiliar para funciones estad√≠sticas (`auxiliar_functions.py`)\n",
    "> - Sugerencias de sintaxis para visualizaciones con seaborn\n",
    "> - Redacci√≥n de comentarios y documentaci√≥n en c√≥digo\n",
    ">\n",
    "> **ChatGPT (GPT-4):**\n",
    "> - Consultas sobre interpretaci√≥n de pruebas estad√≠sticas\n",
    "> - Revisi√≥n de redacci√≥n de secciones del informe\n",
    "> - Sugerencias de estructura para an√°lisis bivariado\n",
    "\n",
    "---\n",
    "\n",
    "## 3.5 Informaci√≥n de Contacto y Entrega\n",
    "\n",
    "### Datos del equipo\n",
    "\n",
    "**Equipo:** Alma de Litio  \n",
    "**Estudiante(s):** Pablo G√≥mez (L√≠der), Emmanuel Vel√°squez, Diego Vidal  \n",
    "**Correo(s):** [COMPLETAR]\n",
    "\n",
    "### Datos de entrega\n",
    "\n",
    "**Profesor:** David Medina Ortiz  \n",
    "**Correo del profesor:** david.medina@umag.cl  \n",
    "**Fecha l√≠mite:** Viernes 15 de noviembre de 2025, 13:00 hrs (hora Santiago)  \n",
    "**Formato de entrega:** Archivo comprimido `.tar.gz` o `.zip` enviado por correo electr√≥nico\n",
    "\n",
    "### Preguntas y consultas\n",
    "\n",
    "**Plazo para consultas:** Hasta el jueves 14 de noviembre de 2025, 12:00 hrs (hora Santiago)\n",
    "\n",
    "---\n",
    "\n",
    "**Fin del documento**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
