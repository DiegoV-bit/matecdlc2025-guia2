{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5f3695",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos - Diabetes Gestacional (GDM)\n",
    "\n",
    "**Universidad de Magallanes**  \n",
    "**Facultad de Ingenier√≠a, Departamento de Ingenier√≠a en Computaci√≥n**  \n",
    "**Asignatura:** Matem√°tica para Ciencias de la Computaci√≥n  \n",
    "**Profesor:** David Medina Ortiz  \n",
    "\n",
    "---\n",
    "\n",
    "**Estudiante(s):** [Nombre(s) del/los estudiante(s)]  \n",
    "**Fecha de entrega:** 15 de noviembre de 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## Tabla de Progreso Global\n",
    "\n",
    "| Secci√≥n | T√≠tulo | Progreso | Estado |\n",
    "|---------|--------|----------|--------|\n",
    "| 1 | Descripci√≥n General del Dataset | 100% | ‚úÖ |\n",
    "| 2.1 | An√°lisis Exploratorio de Datos (EDA) | 56% | üü° |\n",
    "| 2.2 | Intervalos de Confianza | 54% | üü° |\n",
    "| 2.3 | Pruebas de Hip√≥tesis | 8% | üî¥ |\n",
    "| 2.4 | Evaluaci√≥n de Normalidad | 85% | üü¢ |\n",
    "| 2.5 | An√°lisis Bivariado | 28% | üî¥ |\n",
    "| 2.6 | Interpretaci√≥n Cl√≠nica y Conclusiones | 0% | üî¥ |\n",
    "| 3 | Entregables y Archivos | 100% | ‚úÖ |\n",
    "| **GLOBAL** | **Progreso Total** | **39%** | üü° |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64237ba6",
   "metadata": {},
   "source": [
    "# 1. Descripci√≥n General del Dataset\n",
    "\n",
    "## Contexto\n",
    "\n",
    "Este trabajo utiliza un **dataset sint√©tico** que simula informaci√≥n cl√≠nica del **primer trimestre del embarazo** para el estudio de la **diabetes gestacional (GDM)**. El objetivo es caracterizar estad√≠sticamente los datos y explorar asociaciones entre variables cl√≠nicas y el riesgo de desarrollar GDM.\n",
    "\n",
    "## Caracter√≠sticas del Dataset\n",
    "\n",
    "- **N**: Aproximadamente 1500 registros de pacientes embarazadas\n",
    "- **Variables incluidas**:\n",
    "  - **Cl√≠nicas**: edad, IMC pregestacional, presi√≥n arterial (sist√≥lica, diast√≥lica, MAP), semanas de gestaci√≥n\n",
    "  - **Bioqu√≠micas**: FPG (glucosa en ayunas), HbA1c, insulina, HOMA-IR, triglic√©ridos, HDL\n",
    "  - **Factores de riesgo**: paridad, antecedentes familiares de diabetes tipo 2, GDM previa, PCOS, tabaquismo\n",
    "  - **Estilo de vida**: nivel de actividad f√≠sica, puntuaci√≥n de dieta (0-100)\n",
    "  - **Variable objetivo**: `label_gdm` (0 = No GDM, 1 = GDM)\n",
    "\n",
    "## Caracter√≠sticas Especiales\n",
    "\n",
    "- **Datos faltantes**: Presencia de valores nulos con patrones MCAR (Missing Completely At Random) y MAR (Missing At Random)\n",
    "- **Outliers**: El dataset contiene valores at√≠picos que requieren identificaci√≥n y tratamiento\n",
    "- **Desbalance de clases**: Aproximadamente 17% de casos positivos de GDM\n",
    "- **Tipos de variables**: Mixto (continuas, discretas y categ√≥ricas binarias)\n",
    "\n",
    "## Objetivo del An√°lisis\n",
    "\n",
    "Realizar un an√°lisis exploratorio exhaustivo que permita:\n",
    "1. Caracterizar la distribuci√≥n de las variables\n",
    "2. Identificar patrones y asociaciones relevantes\n",
    "3. Comparar grupos (GDM vs No-GDM)\n",
    "4. Evaluar supuestos estad√≠sticos\n",
    "5. Generar insights cl√≠nicos para la comprensi√≥n del riesgo de GDM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0aa53b",
   "metadata": {},
   "source": [
    "# 2. Actividades Desarrolladas\n",
    "\n",
    "Esta secci√≥n contiene el an√°lisis exploratorio organizado por subsecciones seg√∫n la gu√≠a pr√°ctica.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ad0a9",
   "metadata": {},
   "source": [
    "## 2.1 An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "**Estado**: üü° 56% completado  \n",
    "**Pendiente**: Visualizaciones adicionales e interpretaci√≥n textual de variables\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Carga de datos y verificaci√≥n de dimensiones\n",
    "- ‚úÖ An√°lisis de tipos de datos\n",
    "- ‚úÖ Detecci√≥n de valores faltantes\n",
    "- ‚úÖ Estad√≠stica descriptiva (media, mediana, IQR, percentiles)\n",
    "- ‚úÖ Detecci√≥n de outliers por IQR e Isolation Forest\n",
    "- ‚úÖ Filtrado de outliers por votaci√≥n\n",
    "- ‚úÖ Visualizaciones iniciales (histogramas, boxplots, violinplots)\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Histogramas individuales con interpretaci√≥n\n",
    "- ‚è≥ Superposici√≥n de curva normal en histogramas\n",
    "- ‚è≥ Gr√°ficos de densidad (KDE) para variables clave\n",
    "- ‚è≥ Interpretaci√≥n textual detallada por variable\n",
    "- ‚è≥ Documentaci√≥n de estrategia para outliers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585aa278",
   "metadata": {},
   "source": [
    "### Importaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from auxiliar_functions import *\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9c3e4",
   "metadata": {},
   "source": [
    "### Carga y exploraci√≥n inicial del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f52dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "df_data = pd.read_csv(\"gdm_first_trimester_ml_dataset.csv\")\n",
    "\n",
    "# Primeras filas\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "print(f\"Dimensiones: {df_data.shape}\")\n",
    "print(f\"Total de registros: {df_data.shape[0]}\")\n",
    "print(f\"Total de variables: {df_data.shape[1]}\")\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de la variable objetivo\n",
    "print(\"Distribuci√≥n de GDM:\")\n",
    "print(df_data[\"label_gdm\"].value_counts())\n",
    "print(f\"\\nProporci√≥n de casos positivos: {df_data['label_gdm'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos\n",
    "print(\"Tipos de datos por variable:\")\n",
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d8bb4",
   "metadata": {},
   "source": [
    "### An√°lisis de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls = df_data.isna().astype(int)\n",
    "df_summary_null = generate_df_counts(df_nulls, columns_name=[\"descriptor\", \"count_Nulls\", \"count_Falses\"])\n",
    "print(\"Resumen de valores faltantes:\")\n",
    "df_summary_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27535ff4",
   "metadata": {},
   "source": [
    "### Estad√≠stica descriptiva\n",
    "\n",
    "Definimos las variables categ√≥ricas que se excluir√°n del an√°lisis descriptivo de variables continuas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_ignore = [\n",
    "    \"parity\", \n",
    "    \"family_history_t2d\",\n",
    "    \"previous_gdm\",\n",
    "    \"pcos\", \n",
    "    \"smoking_first_trimester\",\n",
    "    \"label_gdm\",\n",
    "    \"physical_activity_level\"\n",
    "]\n",
    "\n",
    "print(\"Variables categ√≥ricas/binarias a excluir del an√°lisis descriptivo:\")\n",
    "print(columns_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b36d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠stica descriptiva para todas las variables\n",
    "print(\"Estad√≠sticas descriptivas del dataset completo:\")\n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb410c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_descriptors = []\n",
    "\n",
    "for column in df_data.columns:\n",
    "    if column not in columns_to_ignore:\n",
    "        descriptive_values = df_data[column].describe()\n",
    "\n",
    "        IQR = descriptive_values[\"75%\"] - descriptive_values[\"25%\"]\n",
    "        min_value, max_value = get_range_outlier(\n",
    "            descriptive_values[\"25%\"], \n",
    "            descriptive_values[\"75%\"], \n",
    "            IQR)\n",
    "\n",
    "        row = {\n",
    "            \"descriptor\" : column,\n",
    "            \"mean\":descriptive_values[\"mean\"],\n",
    "            \"std\" :descriptive_values[\"std\"],\n",
    "            \"median\" : descriptive_values[\"50%\"],\n",
    "            \"IQR\" : IQR,\n",
    "            \"25%\" : descriptive_values[\"25%\"],\n",
    "            \"75%\" :descriptive_values[\"75%\"],\n",
    "            \"min_value_for_outlier\" : min_value,\n",
    "            \"max_value_for_outlier\" : max_value\n",
    "\n",
    "        }\n",
    "        statistical_descriptors.append(row)\n",
    "\n",
    "df_statistical = pd.DataFrame(statistical_descriptors)\n",
    "print(\"Estad√≠sticas descriptivas con IQR y umbrales para outliers:\")\n",
    "df_statistical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b06d9",
   "metadata": {},
   "source": [
    "### Detecci√≥n de outliers\n",
    "\n",
    "**Nota**: Se implementa detecci√≥n por IQR e Isolation Forest con sistema de votaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d525017",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Intervalos de Confianza\n",
    "\n",
    "**Estado**: üü° 54% completado  \n",
    "**Pendiente**: IC para proporciones, diferencias de medias e interpretaci√≥n cl√≠nica\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Funciones de c√°lculo de IC implementadas en `auxiliar_functions.py`\n",
    "- ‚úÖ IC para media y varianza de IMC, FPG, HbA1c con m√∫ltiples tama√±os de muestra\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ IC para medias de: HDL, presi√≥n arterial (sist√≥lica, diast√≥lica, MAP), triglic√©ridos\n",
    "- ‚è≥ IC para proporciones (fumadoras, antecedentes familiares, PCOS, GDM previa)\n",
    "- ‚è≥ IC para diferencia de medias entre grupos GDM vs No-GDM\n",
    "- ‚è≥ Interpretaci√≥n cl√≠nica comparando con rangos de referencia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ff89c",
   "metadata": {},
   "source": [
    "### C√°lculo de intervalos de confianza para diferentes tama√±os de muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feee6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(10, 100, 10)  # Tama√±os de muestra de 10 a 100\n",
    "print(\"Tama√±os de muestra a evaluar:\")\n",
    "print(n)\n",
    "\n",
    "nro_tamanhos = n.size\n",
    "np.random.seed(42)\n",
    "\n",
    "# Intervalos de confianza\n",
    "for i in range(0, nro_tamanhos):\n",
    "    df_mini = pd.DataFrame()\n",
    "    picked_up_indexs = []\n",
    "    index = None\n",
    "\n",
    "    for j in range(0, int(n[i])):    \n",
    "        while index in picked_up_indexs:\n",
    "            index = np.random.randint(0, df_data.shape[0])\n",
    "            df_mini = pd.concat([df_mini, df_data.iloc[[index]]])\n",
    "        picked_up_indexs.append(index)\n",
    "    \n",
    "    # Intervalos de confianza para variables clave\n",
    "    interesting_descriptors_names = [\"bmi_prepreg_kg_m2\", \"fpg_mmol_l\", \"hba1c_percent\"]\n",
    "\n",
    "    for descriptor_name in interesting_descriptors_names:\n",
    "        descriptor = df_mini[descriptor_name]\n",
    "        descriptor_mean = descriptor.mean()\n",
    "        descriptor_std = descriptor.std()\n",
    "        IC_mean = calculate_ic_mean(descriptor_mean, descriptor_std, int(n[i]))\n",
    "        IC_std = calculate_ic_std(descriptor_std, int(n[i]))\n",
    "        print(f\"Para n={int(n[i])} el intervalo de confianza para la media (Œº) del descriptor '{descriptor_name}' es [{IC_mean[0]:.4f}, {IC_mean[1]:.4f}]\")\n",
    "        print(f\"Para n={int(n[i])} el intervalo de confianza para la varianza (œÉ¬≤) del descriptor '{descriptor_name}' es [{IC_std[0]:.4f}, {IC_std[1]:.4f}]\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c86ff4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Pruebas de Hip√≥tesis\n",
    "\n",
    "**Estado**: üî¥ 8% completado - **CR√çTICO**  \n",
    "**Pendiente**: Casi todas las pruebas de hip√≥tesis\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Funci√≥n `compare_two_groups_numeric` implementada (t-test/Welch/Mann-Whitney autom√°tico)\n",
    "- ‚úÖ Comparaci√≥n preliminar de presi√≥n arterial (sist√≥lica, diast√≥lica, MAP) entre grupos GDM\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Formular H‚ÇÄ y H‚ÇÅ para todas las comparaciones\n",
    "- ‚è≥ Comparar IMC, FPG, HbA1c entre GDM vs No-GDM\n",
    "- ‚è≥ Comparar dieta seg√∫n nivel de actividad f√≠sica (ANOVA/Kruskal-Wallis)\n",
    "- ‚è≥ Pruebas de proporciones (chi¬≤ o z): antecedentes familiares, PCOS, tabaquismo vs GDM\n",
    "- ‚è≥ Reportar tama√±o de efecto (d de Cohen o r) para todas las pruebas\n",
    "- ‚è≥ Interpretar resultados en contexto cl√≠nico\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a716d3b",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de presi√≥n arterial entre grupos GDM (ejemplo preliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_groups_numeric(df, y_col, group_col=\"label_gdm\", alpha=0.05, tail=\"two-sided\"):\n",
    "    \"\"\"\n",
    "    Compara una variable num√©rica (y_col) entre dos grupos binarios (group_col).\n",
    "    Verifica supuestos: normalidad por grupo (Shapiro) y homogeneidad (Levene).\n",
    "    Decide autom√°ticamente entre:\n",
    "      - t de Student cl√°sico (varianzas iguales)\n",
    "      - Welch t-test (varianzas desiguales)\n",
    "      - Mann‚ÄìWhitney U (si falla normalidad)\n",
    "    Retorna un dict con todo lo necesario para el informe.\n",
    "    \"\"\"\n",
    "    d = df[[y_col, group_col]].dropna()\n",
    "    g0 = d[d[group_col] == 0][y_col].astype(float).values\n",
    "    g1 = d[d[group_col] == 1][y_col].astype(float).values\n",
    "\n",
    "    # Hip√≥tesis\n",
    "    H0 = f\"Œº_{y_col}|GDM=0 == Œº_{y_col}|GDM=1\"\n",
    "    H1 = f\"Œº_{y_col}|GDM=0 != Œº_{y_col}|GDM=1\" if tail==\"two-sided\" else f\"Œº diferencias unilaterales ({tail})\"\n",
    "\n",
    "    # Normalidad por grupo (solo si n>=3)\n",
    "    sh0 = stats.shapiro(g0) if len(g0) >= 3 else (np.nan, np.nan)\n",
    "    sh1 = stats.shapiro(g1) if len(g1) >= 3 else (np.nan, np.nan)\n",
    "    normal_ok = (not np.isnan(sh0[1]) and sh0[1] > alpha) and (not np.isnan(sh1[1]) and sh1[1] > alpha)\n",
    "\n",
    "    # Homogeneidad de varianzas (Levene)\n",
    "    lev = stats.levene(g0, g1, center='median')\n",
    "    equal_var = lev.pvalue > alpha\n",
    "\n",
    "    # Elecci√≥n de prueba\n",
    "    if normal_ok:\n",
    "        res = stats.ttest_ind(g0, g1, equal_var=equal_var, alternative=\"two-sided\")\n",
    "        test_name = \"t-test (Welch)\" if not equal_var else \"t-test (varianzas iguales)\"\n",
    "        stat, p = res.statistic, res.pvalue\n",
    "    else:\n",
    "        res = stats.mannwhitneyu(g0, g1, alternative=\"two-sided\")\n",
    "        test_name = \"Mann‚ÄìWhitney U\"\n",
    "        stat, p = res.statistic, res.pvalue\n",
    "\n",
    "    decision = \"Rechazo H0\" if p < alpha else \"No rechazo H0\"\n",
    "\n",
    "    return {\n",
    "        \"variable\": y_col,\n",
    "        \"n_gdm0\": len(g0), \"mean_gdm0\": np.mean(g0), \"sd_gdm0\": np.std(g0, ddof=1),\n",
    "        \"n_gdm1\": len(g1), \"mean_gdm1\": np.mean(g1), \"sd_gdm1\": np.std(g1, ddof=1),\n",
    "        \"shapiro_g0_p\": (np.nan if np.isnan(sh0[1]) else sh0[1]),\n",
    "        \"shapiro_g1_p\": (np.nan if np.isnan(sh1[1]) else sh1[1]),\n",
    "        \"levene_p\": lev.pvalue,\n",
    "        \"test\": test_name, \"stat\": stat, \"p_value\": p,\n",
    "        \"alpha\": alpha, \"decision\": decision,\n",
    "        \"H0\": H0, \"H1\": H1\n",
    "    }\n",
    "\n",
    "# Ejemplo: Comparaci√≥n de presi√≥n arterial\n",
    "print(\"Comparaci√≥n de presi√≥n arterial entre grupos GDM vs No-GDM:\")\n",
    "print(\"=\" * 70)\n",
    "for col in [\"systolic_bp_mmHg\", \"diastolic_bp_mmHg\", \"map_mmHg\"]:\n",
    "    out = compare_two_groups_numeric(df_data, y_col=col, group_col=\"label_gdm\", alpha=0.05)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87efb4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Evaluaci√≥n de Normalidad\n",
    "\n",
    "**Estado**: üü¢ 85% completado - **CASI COMPLETO**  \n",
    "**Pendiente**: Solo visualizaciones (QQ-plots) y transformaciones\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Prueba de Shapiro-Wilk para todas las variables continuas\n",
    "- ‚úÖ Prueba de Kolmogorov-Smirnov (Lilliefors) para todas las variables continuas\n",
    "- ‚úÖ Resumen tabular de resultados con decisi√≥n (Normal / No normal)\n",
    "- ‚úÖ Comparaci√≥n de ambos tests y priorizaci√≥n de Shapiro-Wilk\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Generar QQ-plots para cada variable continua\n",
    "- ‚è≥ Histogramas con curva normal superpuesta\n",
    "- ‚è≥ Probar transformaciones (log, Box-Cox) en variables asim√©tricas\n",
    "- ‚è≥ Re-evaluar normalidad post-transformaci√≥n\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c471b0",
   "metadata": {},
   "source": [
    "### Pruebas de normalidad: Shapiro-Wilk y Kolmogorov-Smirnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables = [\n",
    "    \"age_years\", \"bmi_prepreg_kg_m2\", \"systolic_bp_mmHg\", \"diastolic_bp_mmHg\", \n",
    "    \"map_mmHg\", \"gestational_weeks\", \"fpg_mmol_l\", \"hba1c_percent\", \n",
    "    \"insulin_uIU_ml\", \"homa_ir\", \"triglycerides_mmol_l\", \"hdl_mmol_l\", \n",
    "    \"physical_activity_level\", \"diet_score_0_100\"\n",
    "]\n",
    "\n",
    "# Inicializar estructuras\n",
    "clean_data_descriptors = []\n",
    "n_val = []\n",
    "n_invalid = []\n",
    "\n",
    "# Limpiar NaN por variable\n",
    "for var in continuous_variables:\n",
    "    valid_data = df_data[var].dropna()\n",
    "    n_validos = valid_data.size\n",
    "    n_faltantes = df_data[var].isna().sum()\n",
    "\n",
    "    clean_data_descriptors.append(valid_data)\n",
    "    n_val.append(n_validos)\n",
    "    n_invalid.append(n_faltantes)\n",
    "\n",
    "# Prueba de normalidad\n",
    "normality_results = []\n",
    "alpha = 0.05\n",
    "\n",
    "# Evaluar cada variable\n",
    "for idx, var in enumerate(continuous_variables):\n",
    "    x = clean_data_descriptors[idx]\n",
    "\n",
    "    # Shapiro‚ÄìWilk\n",
    "    W, p_sw = stats.shapiro(x)\n",
    "    \n",
    "    # KS-Lilliefors (usando par√°metros estimados)\n",
    "    mu, sigma = x.mean(), x.std(ddof=1)\n",
    "    D, p_ks = stats.kstest(x, 'norm', args=(mu, sigma))\n",
    "    \n",
    "    # Decisi√≥n\n",
    "    decision_sw = \"Normal\" if p_sw >= alpha else \"No normal\"\n",
    "    decision_ks = \"Normal\" if p_ks >= alpha else \"No normal\"\n",
    "    \n",
    "    # Guardar resultado\n",
    "    normality_results.append({\n",
    "        \"Variable\": var,\n",
    "        \"n\": len(x),\n",
    "        \"SW_W\": W,\n",
    "        \"SW_p\": p_sw,\n",
    "        \"SW_decisi√≥n\": decision_sw,\n",
    "        \"KS_D\": D,\n",
    "        \"KS_p\": p_ks,\n",
    "        \"KS_decisi√≥n\": decision_ks\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Resultados de pruebas de normalidad:\")\n",
    "print(\"=\" * 100)\n",
    "for result in normality_results:\n",
    "    print(f\"\\n{result['Variable']}:\")\n",
    "    print(f\"  n={result['n']}\")\n",
    "    print(f\"  Shapiro-Wilk: W={result['SW_W']:.4f}, p={result['SW_p']:.4f} ‚Üí {result['SW_decisi√≥n']}\")\n",
    "    print(f\"  KS-Lilliefors: D={result['KS_D']:.4f}, p={result['KS_p']:.4f} ‚Üí {result['KS_decisi√≥n']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16a148",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 An√°lisis Bivariado\n",
    "\n",
    "**Estado**: üî¥ 28% completado - **CR√çTICO**  \n",
    "**Pendiente**: Visualizaciones completas e interpretaci√≥n cl√≠nica\n",
    "\n",
    "### Tareas realizadas:\n",
    "- ‚úÖ Matriz de correlaci√≥n de Pearson calculada\n",
    "- ‚úÖ Heatmap de correlaci√≥n generado\n",
    "- ‚úÖ Pairplot preliminar con visualizaci√≥n por grupo GDM\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ Identificar y discutir correlaciones fuertes (|r| > 0.7)\n",
    "- ‚è≥ Scatterplots con regresi√≥n para pares clave (FPG vs HbA1c, Insulina vs HOMA-IR, etc.)\n",
    "- ‚è≥ Incluir ecuaci√≥n de regresi√≥n y R¬≤ en gr√°ficos\n",
    "- ‚è≥ Boxplots comparativos por grupo GDM para variables clave\n",
    "- ‚è≥ Interpretaci√≥n cl√≠nica de asociaciones encontradas\n",
    "- ‚è≥ Relacionar hallazgos con literatura sobre GDM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bf1b7",
   "metadata": {},
   "source": [
    "### Matriz de correlaci√≥n y heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: Esta celda usa df_filter del prototipo. Asegurar que est√© creado previamente con:\n",
    "# df_filter = df_data[df_data[\"vote_outlier\"]<3].drop(columns=['is_outlier_by_IQR', etc.])\n",
    "\n",
    "# Calcular correlaci√≥n de Pearson\n",
    "df_corr_pearson = df_filter.drop(columns=[\"label_gdm\"]).corr(method=\"pearson\")\n",
    "\n",
    "# Visualizar heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(data=df_corr_pearson, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar_kws={'label': 'Correlaci√≥n de Pearson'})\n",
    "plt.title(\"Matriz de Correlaci√≥n de Pearson - Variables Continuas\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelaciones fuertes encontradas (|r| > 0.7):\")\n",
    "print(\"=\" * 50)\n",
    "# Identificar correlaciones fuertes\n",
    "for i in range(len(df_corr_pearson.columns)):\n",
    "    for j in range(i+1, len(df_corr_pearson.columns)):\n",
    "        corr_value = df_corr_pearson.iloc[i, j]\n",
    "        if abs(corr_value) > 0.7:\n",
    "            print(f\"{df_corr_pearson.columns[i]} vs {df_corr_pearson.columns[j]}: r = {corr_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce017ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.6 Interpretaci√≥n Cl√≠nica y Conclusiones\n",
    "\n",
    "**Estado**: üî¥ 0% completado - **CR√çTICO**  \n",
    "**Pendiente**: Toda la secci√≥n de conclusiones\n",
    "\n",
    "### Tareas pendientes:\n",
    "- ‚è≥ S√≠ntesis de variables con distribuci√≥n no normal y consecuencias\n",
    "- ‚è≥ Resumen de diferencias significativas entre grupos (GDM vs No-GDM)\n",
    "- ‚è≥ Destacar direcci√≥n de diferencias (qu√© grupo tiene valores m√°s altos/bajos)\n",
    "- ‚è≥ Listar correlaciones cl√≠nicamente relevantes y su significado\n",
    "- ‚è≥ Discutir posibles relaciones causales vs correlaci√≥n espuria\n",
    "- ‚è≥ Comentar sobre datos faltantes y su posible impacto\n",
    "- ‚è≥ Discutir sesgos potenciales en la muestra\n",
    "- ‚è≥ Mencionar variables confusoras no controladas\n",
    "- ‚è≥ Proponer an√°lisis multivariado (regresi√≥n log√≠stica)\n",
    "- ‚è≥ Sugerir validaci√≥n cruzada de modelos predictivos\n",
    "- ‚è≥ Recomendar estudios adicionales\n",
    "\n",
    "---\n",
    "\n",
    "### Secci√≥n a completar\n",
    "\n",
    "**Estructura sugerida para las conclusiones:**\n",
    "\n",
    "1. **Resumen de hallazgos principales**\n",
    "   - Variables no normales y sus implicancias\n",
    "   - Diferencias significativas entre grupos\n",
    "   - Correlaciones relevantes encontradas\n",
    "\n",
    "2. **Interpretaci√≥n cl√≠nica**\n",
    "   - Significado de las diferencias entre GDM vs No-GDM\n",
    "   - Relevancia de las correlaciones para el diagn√≥stico/pron√≥stico\n",
    "   - Comparaci√≥n con rangos cl√≠nicos de referencia\n",
    "\n",
    "3. **Limitaciones del estudio**\n",
    "   - Impacto de datos faltantes\n",
    "   - Sesgos y variables confusoras\n",
    "   - Naturaleza del dataset sint√©tico\n",
    "\n",
    "4. **Pr√≥ximos pasos**\n",
    "   - An√°lisis multivariado recomendado\n",
    "   - Validaci√≥n de modelos predictivos\n",
    "   - Estudios complementarios necesarios\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfa837",
   "metadata": {},
   "source": [
    "# 3. Entregables y Archivos Adjuntos\n",
    "\n",
    "## Archivos incluidos en la entrega\n",
    "\n",
    "Este trabajo pr√°ctico incluye los siguientes archivos que deben ser entregados en un archivo comprimido (`.tar.gz` o `.zip`):\n",
    "\n",
    "### Archivos principales\n",
    "\n",
    "1. **`Entregable.ipynb`** (este documento)\n",
    "   - Notebook principal con todo el an√°lisis organizado por secciones\n",
    "   - Incluye c√≥digo, visualizaciones e interpretaciones\n",
    "   - Indicadores de progreso por secci√≥n\n",
    "\n",
    "2. **`gdm_first_trimester_ml_dataset.csv`**\n",
    "   - Dataset original con los datos cl√≠nicos\n",
    "   - N ‚âà 1500 registros de pacientes embarazadas\n",
    "   - Variables cl√≠nicas, bioqu√≠micas y de estilo de vida\n",
    "\n",
    "3. **`gdm_first_trimester_ml_dataset_metadata.json`**\n",
    "   - Metadata del dataset\n",
    "   - Descripci√≥n de variables y tipos de datos\n",
    "   - Informaci√≥n sobre valores faltantes y rangos esperados\n",
    "\n",
    "4. **`auxiliar_functions.py`**\n",
    "   - Funciones auxiliares implementadas para el an√°lisis\n",
    "   - Incluye funciones para:\n",
    "     - C√°lculo de intervalos de confianza (media, varianza, desviaci√≥n)\n",
    "     - Detecci√≥n de outliers\n",
    "     - Generaci√≥n de res√∫menes de conteos\n",
    "     - Otras utilidades\n",
    "\n",
    "### Archivos de referencia y documentaci√≥n\n",
    "\n",
    "5. **`INSTRUCCIONES.md`**\n",
    "   - Gu√≠a pr√°ctica original del profesor\n",
    "   - Descripci√≥n de actividades y entregables\n",
    "   - Criterios de evaluaci√≥n\n",
    "\n",
    "6. **`TASKS.md` / `TASK2.md`**\n",
    "   - Lista detallada de tareas pendientes\n",
    "   - Organizaci√≥n por prioridad (`TASKS.md`) y por secci√≥n (`TASK2.md`)\n",
    "   - Indicadores de progreso y estimaciones de tiempo\n",
    "\n",
    "7. **`README.md` (en carpeta `__pycache__/`)**\n",
    "   - Evaluaci√≥n de estado del progreso\n",
    "   - Retroalimentaci√≥n detallada por secci√≥n\n",
    "   - Porcentajes de avance y correcci√≥n\n",
    "\n",
    "8. **`.gitignore`**\n",
    "   - Configuraci√≥n de archivos ignorados por Git\n",
    "   - Incluye: `__pycache__/`, `*.pyc`, entornos virtuales, etc.\n",
    "\n",
    "### Archivos de trabajo (prototipos)\n",
    "\n",
    "9. **`1_check_data.ipynb`**\n",
    "   - Prototipo inicial del an√°lisis\n",
    "   - Contiene desarrollo del c√≥digo que luego se organiz√≥ en `Entregable.ipynb`\n",
    "\n",
    "10. **`check_data.ipynb`**\n",
    "    - Versi√≥n preliminar del prototipo (obsoleta)\n",
    "\n",
    "---\n",
    "\n",
    "## Herramientas utilizadas\n",
    "\n",
    "### Software y entorno\n",
    "\n",
    "- **Python 3.x**\n",
    "- **Jupyter Notebook / JupyterLab**\n",
    "- **Git** (control de versiones)\n",
    "\n",
    "### Librer√≠as principales\n",
    "\n",
    "- **pandas**: Manipulaci√≥n y an√°lisis de datos\n",
    "- **numpy**: Operaciones num√©ricas y √°lgebra lineal\n",
    "- **matplotlib**: Visualizaci√≥n b√°sica\n",
    "- **seaborn**: Visualizaci√≥n estad√≠stica avanzada\n",
    "- **scipy.stats**: Pruebas estad√≠sticas (Shapiro-Wilk, KS, t-test, Mann-Whitney, Levene, etc.)\n",
    "- **sklearn.ensemble.IsolationForest**: Detecci√≥n de anomal√≠as/outliers\n",
    "\n",
    "### Herramientas de IA (si aplica)\n",
    "\n",
    "**[Indicar aqu√≠ si se us√≥ ChatGPT, GitHub Copilot u otra herramienta de IA, especificando para qu√© tareas]**\n",
    "\n",
    "Ejemplo:\n",
    "> Se utiliz√≥ GitHub Copilot para:\n",
    "> - Generaci√≥n de c√≥digo auxiliar para funciones estad√≠sticas\n",
    "> - Sugerencias de visualizaci√≥n con seaborn\n",
    "> - Redacci√≥n de comentarios y documentaci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "## Instrucciones de ejecuci√≥n\n",
    "\n",
    "### Requisitos previos\n",
    "\n",
    "1. Instalar Python 3.8 o superior\n",
    "2. Instalar las librer√≠as necesarias:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn scipy scikit-learn\n",
    "```\n",
    "\n",
    "### Ejecuci√≥n del notebook\n",
    "\n",
    "1. Abrir `Entregable.ipynb` en Jupyter Notebook/Lab\n",
    "2. Asegurar que `gdm_first_trimester_ml_dataset.csv` y `auxiliar_functions.py` est√°n en el mismo directorio\n",
    "3. Ejecutar las celdas secuencialmente desde el inicio\n",
    "\n",
    "### Notas importantes\n",
    "\n",
    "- Algunas celdas en secciones incompletas (üî¥) pueden fallar si no se han ejecutado celdas previas necesarias\n",
    "- El dataset filtrado `df_filter` se genera en la secci√≥n 2.1 y se usa en secciones posteriores\n",
    "- Los resultados de normalidad (secci√≥n 2.4) deben usarse para justificar elecciones de tests en secci√≥n 2.3\n",
    "\n",
    "---\n",
    "\n",
    "## Informaci√≥n de contacto\n",
    "\n",
    "**Estudiante(s):** [Completar nombre(s)]  \n",
    "**Correo:** [Completar correo(s)]  \n",
    "**Fecha de entrega:** 15 de noviembre de 2025  \n",
    "**Profesor:** David Medina Ortiz  \n",
    "**Correo del profesor:** david.medina@umag.cl\n",
    "\n",
    "---\n",
    "\n",
    "**Fin del documento**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
